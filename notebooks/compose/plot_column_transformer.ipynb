{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "==================================================<br>\n", "Column Transformer with Heterogeneous Data Sources<br>\n", "==================================================<br>\n", "Datasets can often contain components of that require different feature<br>\n", "extraction and processing pipelines.  This scenario might occur when:<br>\n", "1. Your dataset consists of heterogeneous data types (e.g. raster images and<br>\n", "   text captions)<br>\n", "2. Your dataset is stored in a Pandas DataFrame and different columns<br>\n", "   require different processing pipelines.<br>\n", "This example demonstrates how to use<br>\n", ":class:`sklearn.compose.ColumnTransformer` on a dataset containing<br>\n", "different types of features.  We use the 20-newsgroups dataset and compute<br>\n", "standard bag-of-words features for the subject line and body in separate<br>\n", "pipelines as well as ad hoc features on the body. We combine them (with<br>\n", "weights) using a ColumnTransformer and finally train a classifier on the<br>\n", "combined set of features.<br>\n", "The choice of features is not particularly helpful, but serves to illustrate<br>\n", "the technique.<br>\n", ""]}, {"cell_type": "markdown", "metadata": {}, "source": ["Author: Matt Terry <matt.terry@gmail.com><br>\n", "<br>\n", "License: BSD 3 clause"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.base import BaseEstimator, TransformerMixin\n", "from sklearn.datasets import fetch_20newsgroups\n", "from sklearn.decomposition import TruncatedSVD\n", "from sklearn.feature_extraction import DictVectorizer\n", "from sklearn.feature_extraction.text import TfidfVectorizer\n", "from sklearn.metrics import classification_report\n", "from sklearn.pipeline import Pipeline\n", "from sklearn.compose import ColumnTransformer\n", "from sklearn.svm import LinearSVC"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class TextStats(TransformerMixin, BaseEstimator):\n", "    \"\"\"Extract features from each document for DictVectorizer\"\"\"\n", "    def fit(self, x, y=None):\n", "        return self\n", "    def transform(self, posts):\n", "        return [{'length': len(text),\n", "                 'num_sentences': text.count('.')}\n", "                for text in posts]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class SubjectBodyExtractor(TransformerMixin, BaseEstimator):\n", "    \"\"\"Extract the subject & body from a usenet post in a single pass.\n", "    Takes a sequence of strings and produces a dict of sequences.  Keys are\n", "    `subject` and `body`.\n", "    \"\"\"\n", "    def fit(self, x, y=None):\n", "        return self\n", "    def transform(self, posts):\n", "        # construct object dtype array with two columns\n", "        # first column = 'subject' and second column = 'body'\n", "        features = np.empty(shape=(len(posts), 2), dtype=object)\n", "        for i, text in enumerate(posts):\n", "            headers, _, bod = text.partition('\\n\\n')\n", "            features[i, 1] = bod\n", "            prefix = 'Subject:'\n", "            sub = ''\n", "            for line in headers.split('\\n'):\n", "                if line.startswith(prefix):\n", "                    sub = line[len(prefix):]\n", "                    break\n", "            features[i, 0] = sub\n", "        return features"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["pipeline = Pipeline([\n", "    # Extract the subject & body\n", "    ('subjectbody', SubjectBodyExtractor()),\n\n", "    # Use ColumnTransformer to combine the features from subject and body\n", "    ('union', ColumnTransformer(\n", "        [\n", "            # Pulling features from the post's subject line (first column)\n", "            ('subject', TfidfVectorizer(min_df=50), 0),\n\n", "            # Pipeline for standard bag-of-words model for body (second column)\n", "            ('body_bow', Pipeline([\n", "                ('tfidf', TfidfVectorizer()),\n", "                ('best', TruncatedSVD(n_components=50)),\n", "            ]), 1),\n\n", "            # Pipeline for pulling ad hoc features from post's body\n", "            ('body_stats', Pipeline([\n", "                ('stats', TextStats()),  # returns a list of dicts\n", "                ('vect', DictVectorizer()),  # list of dicts -> feature matrix\n", "            ]), 1),\n", "        ],\n\n", "        # weight components in ColumnTransformer\n", "        transformer_weights={\n", "            'subject': 0.8,\n", "            'body_bow': 0.5,\n", "            'body_stats': 1.0,\n", "        }\n", "    )),\n\n", "    # Use a SVC classifier on the combined features\n", "    ('svc', LinearSVC(dual=False)),\n", "], verbose=True)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["limit the list of categories to make running this example faster."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["categories = ['alt.atheism', 'talk.religion.misc']\n", "X_train, y_train = fetch_20newsgroups(random_state=1,\n", "                                      subset='train',\n", "                                      categories=categories,\n", "                                      remove=('footers', 'quotes'),\n", "                                      return_X_y=True)\n", "X_test, y_test = fetch_20newsgroups(random_state=1,\n", "                                    subset='test',\n", "                                    categories=categories,\n", "                                    remove=('footers', 'quotes'),\n", "                                    return_X_y=True)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["pipeline.fit(X_train, y_train)\n", "y_pred = pipeline.predict(X_test)\n", "print(classification_report(y_test, y_pred))"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}