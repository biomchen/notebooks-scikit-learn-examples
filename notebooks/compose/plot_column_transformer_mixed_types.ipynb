{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "===================================<br>\n", "Column Transformer with Mixed Types<br>\n", "===================================<br>\n", "This example illustrates how to apply different preprocessing and<br>\n", "feature extraction pipelines to different subsets of features,<br>\n", "using :class:`sklearn.compose.ColumnTransformer`.<br>\n", "This is particularly handy for the case of datasets that contain<br>\n", "heterogeneous data types, since we may want to scale the<br>\n", "numeric features and one-hot encode the categorical ones.<br>\n", "In this example, the numeric data is standard-scaled after<br>\n", "mean-imputation, while the categorical data is one-hot<br>\n", "encoded after imputing missing values with a new category<br>\n", "(``'missing'``).<br>\n", "Finally, the preprocessing pipeline is integrated in a<br>\n", "full prediction pipeline using :class:`sklearn.pipeline.Pipeline`,<br>\n", "together with a simple classification model.<br>\n", ""]}, {"cell_type": "markdown", "metadata": {}, "source": ["Author: Pedro Morales <part.morales@gmail.com><br>\n", "<br>\n", "License: BSD 3 clause"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.compose import ColumnTransformer\n", "from sklearn.datasets import fetch_openml\n", "from sklearn.pipeline import Pipeline\n", "from sklearn.impute import SimpleImputer\n", "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n", "from sklearn.linear_model import LogisticRegression\n", "from sklearn.model_selection import train_test_split, GridSearchCV"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["np.random.seed(0)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Load data from https://www.openml.org/d/40945"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X, y = fetch_openml(\"titanic\", version=1, as_frame=True, return_X_y=True)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Alternatively X and y can be obtained directly from the frame attribute:<br>\n", "X = titanic.frame.drop('survived', axis=1)<br>\n", "y = titanic.frame['survived']"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We will train our classifier with the following features:<br>\n", "Numeric Features:<br>\n", "- age: float.<br>\n", "- fare: float.<br>\n", "Categorical Features:<br>\n", "- embarked: categories encoded as strings {'C', 'S', 'Q'}.<br>\n", "- sex: categories encoded as strings {'female', 'male'}.<br>\n", "- pclass: ordinal integers {1, 2, 3}."]}, {"cell_type": "markdown", "metadata": {}, "source": ["We create the preprocessing pipelines for both numeric and categorical data."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["numeric_features = ['age', 'fare']\n", "numeric_transformer = Pipeline(steps=[\n", "    ('imputer', SimpleImputer(strategy='median')),\n", "    ('scaler', StandardScaler())])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["categorical_features = ['embarked', 'sex', 'pclass']\n", "categorical_transformer = Pipeline(steps=[\n", "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n", "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["preprocessor = ColumnTransformer(\n", "    transformers=[\n", "        ('num', numeric_transformer, numeric_features),\n", "        ('cat', categorical_transformer, categorical_features)])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Append classifier to preprocessing pipeline.<br>\n", "Now we have a full prediction pipeline."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["clf = Pipeline(steps=[('preprocessor', preprocessor),\n", "                      ('classifier', LogisticRegression())])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["clf.fit(X_train, y_train)\n", "print(\"model score: %.3f\" % clf.score(X_test, y_test))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#############################################################################<br>\n", "Using the prediction pipeline in a grid search<br>\n", "#############################################################################<br>\n", "Grid search can also be performed on the different preprocessing steps<br>\n", "defined in the ``ColumnTransformer`` object, together with the classifier's<br>\n", "hyperparameters as part of the ``Pipeline``.<br>\n", "We will search for both the imputer strategy of the numeric preprocessing<br>\n", "and the regularization parameter of the logistic regression using<br>\n", ":class:`sklearn.model_selection.GridSearchCV`."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["param_grid = {\n", "    'preprocessor__num__imputer__strategy': ['mean', 'median'],\n", "    'classifier__C': [0.1, 1.0, 10, 100],\n", "}"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["grid_search = GridSearchCV(clf, param_grid, cv=10)\n", "grid_search.fit(X_train, y_train)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print((\"best logistic regression from grid search: %.3f\"\n", "       % grid_search.score(X_test, y_test)))"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}