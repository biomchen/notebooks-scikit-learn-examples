{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["#!/usr/bin/env python\n", "# -*- coding: utf-8 -*-\n", "\"\"\"\n", "=================================================================\n", "Selecting dimensionality reduction with Pipeline and GridSearchCV\n", "================================================================="]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["This example constructs a pipeline that does dimensionality\n", "reduction followed by prediction with a support vector\n", "classifier. It demonstrates the use of ``GridSearchCV`` and\n", "``Pipeline`` to optimize over different classes of estimators in a\n", "single CV run -- unsupervised ``PCA`` and ``NMF`` dimensionality\n", "reductions are compared to univariate feature selection during\n", "the grid search."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["Additionally, ``Pipeline`` can be instantiated with the ``memory``\n", "argument to memoize the transformers within the pipeline, avoiding to fit\n", "again the same transformers over and over."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["Note that the use of ``memory`` to enable caching becomes interesting when the\n", "fitting of a transformer is costly."]}, {"cell_type": "markdown", "metadata": {}, "source": ["#############################################################################"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["Illustration of ``Pipeline`` and ``GridSearchCV``\n", "###############################################################################"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["This section illustrates the use of a ``Pipeline`` with ``GridSearchCV``\n", "\"\"\""]}, {"cell_type": "markdown", "metadata": {}, "source": ["Authors: Robert McGibbon, Joel Nothman, Guillaume Lemaitre"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "import matplotlib.pyplot as plt\n", "from sklearn.datasets import load_digits\n", "from sklearn.model_selection import GridSearchCV\n", "from sklearn.pipeline import Pipeline\n", "from sklearn.svm import LinearSVC\n", "from sklearn.decomposition import PCA, NMF\n", "from sklearn.feature_selection import SelectKBest, chi2"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(__doc__)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["pipe = Pipeline([\n", "    # the reduce_dim stage is populated by the param_grid\n", "    ('reduce_dim', 'passthrough'),\n", "    ('classify', LinearSVC(dual=False, max_iter=10000))\n", "])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["N_FEATURES_OPTIONS = [2, 4, 8]\n", "C_OPTIONS = [1, 10, 100, 1000]\n", "param_grid = [\n", "    {\n", "        'reduce_dim': [PCA(iterated_power=7), NMF()],\n", "        'reduce_dim__n_components': N_FEATURES_OPTIONS,\n", "        'classify__C': C_OPTIONS\n", "    },\n", "    {\n", "        'reduce_dim': [SelectKBest(chi2)],\n", "        'reduce_dim__k': N_FEATURES_OPTIONS,\n", "        'classify__C': C_OPTIONS\n", "    },\n", "]\n", "reducer_labels = ['PCA', 'NMF', 'KBest(chi2)']"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["grid = GridSearchCV(pipe, n_jobs=1, param_grid=param_grid)\n", "X, y = load_digits(return_X_y=True)\n", "grid.fit(X, y)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["mean_scores = np.array(grid.cv_results_['mean_test_score'])\n", "# scores are in the order of param_grid iteration, which is alphabetical\n", "mean_scores = mean_scores.reshape(len(C_OPTIONS), -1, len(N_FEATURES_OPTIONS))\n", "# select score for best C\n", "mean_scores = mean_scores.max(axis=0)\n", "bar_offsets = (np.arange(len(N_FEATURES_OPTIONS)) *\n", "               (len(reducer_labels) + 1) + .5)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.figure()\n", "COLORS = 'bgrcmyk'\n", "for i, (label, reducer_scores) in enumerate(zip(reducer_labels, mean_scores)):\n", "    plt.bar(bar_offsets + i, reducer_scores, label=label, color=COLORS[i])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.title(\"Comparing feature reduction techniques\")\n", "plt.xlabel('Reduced number of features')\n", "plt.xticks(bar_offsets + len(reducer_labels) / 2, N_FEATURES_OPTIONS)\n", "plt.ylabel('Digit classification accuracy')\n", "plt.ylim((0, 1))\n", "plt.legend(loc='upper left')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#############################################################################<br>\n", "Caching transformers within a ``Pipeline``<br>\n", "#############################################################################<br>\n", "It is sometimes worthwhile storing the state of a specific transformer<br>\n", "since it could be used again. Using a pipeline in ``GridSearchCV`` triggers<br>\n", "such situations. Therefore, we use the argument ``memory`` to enable caching.<br>\n", "<br>\n", ".. warning::<br>\n", "    Note that this example is, however, only an illustration since for this<br>\n", "    specific case fitting PCA is not necessarily slower than loading the<br>\n", "    cache. Hence, use the ``memory`` constructor parameter when the fitting<br>\n", "    of a transformer is costly."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from joblib import Memory\n", "from shutil import rmtree"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Create a temporary folder to store the transformers of the pipeline"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["location = 'cachedir'\n", "memory = Memory(location=location, verbose=10)\n", "cached_pipe = Pipeline([('reduce_dim', PCA()),\n", "                        ('classify', LinearSVC(dual=False, max_iter=10000))],\n", "                       memory=memory)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["This time, a cached pipeline will be used within the grid search"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Delete the temporary cache before exiting"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["memory.clear(warn=False)\n", "rmtree(location)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#############################################################################<br>\n", "The ``PCA`` fitting is only computed at the evaluation of the first<br>\n", "configuration of the ``C`` parameter of the ``LinearSVC`` classifier. The<br>\n", "other configurations of ``C`` will trigger the loading of the cached ``PCA``<br>\n", "estimator data, leading to save processing time. Therefore, the use of<br>\n", "caching the pipeline using ``memory`` is highly beneficial when fitting<br>\n", "a transformer is costly."]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}