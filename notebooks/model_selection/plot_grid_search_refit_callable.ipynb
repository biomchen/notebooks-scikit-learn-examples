{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "==================================================<br>\n", "Balance model complexity and cross-validated score<br>\n", "==================================================<br>\n", "This example balances model complexity and cross-validated score by<br>\n", "finding a decent accuracy within 1 standard deviation of the best accuracy<br>\n", "score while minimising the number of PCA components [1].<br>\n", "The figure shows the trade-off between cross-validated score and the number<br>\n", "of PCA components. The balanced case is when n_components=10 and accuracy=0.88,<br>\n", "which falls into the range within 1 standard deviation of the best accuracy<br>\n", "score.<br>\n", "[1] Hastie, T., Tibshirani, R.,, Friedman, J. (2001). Model Assessment and<br>\n", "Selection. The Elements of Statistical Learning (pp. 219-260). New York,<br>\n", "NY, USA: Springer New York Inc..<br>\n", "<br>\n", "Author: Wenhao Zhang <wenhaoz@ucla.edu>"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(__doc__)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "import matplotlib.pyplot as plt"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.datasets import load_digits\n", "from sklearn.decomposition import PCA\n", "from sklearn.model_selection import GridSearchCV\n", "from sklearn.pipeline import Pipeline\n", "from sklearn.svm import LinearSVC"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def lower_bound(cv_results):\n", "    \"\"\"\n", "    Calculate the lower bound within 1 standard deviation\n", "    of the best `mean_test_scores`.\n", "    Parameters\n", "    ----------\n", "    cv_results : dict of numpy(masked) ndarrays\n", "        See attribute cv_results_ of `GridSearchCV`\n", "    Returns\n", "    -------\n", "    float\n", "        Lower bound within 1 standard deviation of the\n", "        best `mean_test_score`.\n", "    \"\"\"\n", "    best_score_idx = np.argmax(cv_results['mean_test_score'])\n", "    return (cv_results['mean_test_score'][best_score_idx]\n", "            - cv_results['std_test_score'][best_score_idx])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def best_low_complexity(cv_results):\n", "    \"\"\"\n", "    Balance model complexity with cross-validated score.\n", "    Parameters\n", "    ----------\n", "    cv_results : dict of numpy(masked) ndarrays\n", "        See attribute cv_results_ of `GridSearchCV`.\n", "    Return\n", "    ------\n", "    int\n", "        Index of a model that has the fewest PCA components\n", "        while has its test score within 1 standard deviation of the best\n", "        `mean_test_score`.\n", "    \"\"\"\n", "    threshold = lower_bound(cv_results)\n", "    candidate_idx = np.flatnonzero(cv_results['mean_test_score'] >= threshold)\n", "    best_idx = candidate_idx[cv_results['param_reduce_dim__n_components']\n", "                             [candidate_idx].argmin()]\n", "    return best_idx"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["pipe = Pipeline([\n", "        ('reduce_dim', PCA(random_state=42)),\n", "        ('classify', LinearSVC(random_state=42, C=0.01)),\n", "])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["param_grid = {\n", "    'reduce_dim__n_components': [6, 8, 10, 12, 14]\n", "}"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["grid = GridSearchCV(pipe, cv=10, n_jobs=1, param_grid=param_grid,\n", "                    scoring='accuracy', refit=best_low_complexity)\n", "X, y = load_digits(return_X_y=True)\n", "grid.fit(X, y)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["n_components = grid.cv_results_['param_reduce_dim__n_components']\n", "test_scores = grid.cv_results_['mean_test_score']"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.figure()\n", "plt.bar(n_components, test_scores, width=1.3, color='b')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["lower = lower_bound(grid.cv_results_)\n", "plt.axhline(np.max(test_scores), linestyle='--', color='y',\n", "            label='Best score')\n", "plt.axhline(lower, linestyle='--', color='.5', label='Best score - 1 std')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.title(\"Balance model complexity and cross-validated score\")\n", "plt.xlabel('Number of PCA components used')\n", "plt.ylabel('Digit classification accuracy')\n", "plt.xticks(n_components.tolist())\n", "plt.ylim((0, 1.0))\n", "plt.legend(loc='upper left')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["best_index_ = grid.best_index_"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"The best_index_ is %d\" % best_index_)\n", "print(\"The n_components selected is %d\" % n_components[best_index_])\n", "print(\"The corresponding accuracy score is %.2f\"\n", "      % grid.cv_results_['mean_test_score'][best_index_])\n", "plt.show()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}