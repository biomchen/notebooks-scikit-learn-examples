{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "============================<br>\n", "Underfitting vs. Overfitting<br>\n", "============================<br>\n", "This example demonstrates the problems of underfitting and overfitting and<br>\n", "how we can use linear regression with polynomial features to approximate<br>\n", "nonlinear functions. The plot shows the function that we want to approximate,<br>\n", "which is a part of the cosine function. In addition, the samples from the<br>\n", "real function and the approximations of different models are displayed. The<br>\n", "models have polynomial features of different degrees. We can see that a<br>\n", "linear function (polynomial with degree 1) is not sufficient to fit the<br>\n", "training samples. This is called **underfitting**. A polynomial of degree 4<br>\n", "approximates the true function almost perfectly. However, for higher degrees<br>\n", "the model will **overfit** the training data, i.e. it learns the noise of the<br>\n", "training data.<br>\n", "We evaluate quantitatively **overfitting** / **underfitting** by using<br>\n", "cross-validation. We calculate the mean squared error (MSE) on the validation<br>\n", "set, the higher, the less likely the model generalizes correctly from the<br>\n", "training data.<br>\n", ""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(__doc__)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "import matplotlib.pyplot as plt\n", "from sklearn.pipeline import Pipeline\n", "from sklearn.preprocessing import PolynomialFeatures\n", "from sklearn.linear_model import LinearRegression\n", "from sklearn.model_selection import cross_val_score"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def true_fun(X):\n", "    return np.cos(1.5 * np.pi * X)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["np.random.seed(0)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["n_samples = 30\n", "degrees = [1, 4, 15]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X = np.sort(np.random.rand(n_samples))\n", "y = true_fun(X) + np.random.randn(n_samples) * 0.1"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(14, 5))\n", "for i in range(len(degrees)):\n", "    ax = plt.subplot(1, len(degrees), i + 1)\n", "    plt.setp(ax, xticks=(), yticks=())\n", "    polynomial_features = PolynomialFeatures(degree=degrees[i],\n", "                                             include_bias=False)\n", "    linear_regression = LinearRegression()\n", "    pipeline = Pipeline([(\"polynomial_features\", polynomial_features),\n", "                         (\"linear_regression\", linear_regression)])\n", "    pipeline.fit(X[:, np.newaxis], y)\n\n", "    # Evaluate the models using crossvalidation\n", "    scores = cross_val_score(pipeline, X[:, np.newaxis], y,\n", "                             scoring=\"neg_mean_squared_error\", cv=10)\n", "    X_test = np.linspace(0, 1, 100)\n", "    plt.plot(X_test, pipeline.predict(X_test[:, np.newaxis]), label=\"Model\")\n", "    plt.plot(X_test, true_fun(X_test), label=\"True function\")\n", "    plt.scatter(X, y, edgecolor='b', s=20, label=\"Samples\")\n", "    plt.xlabel(\"x\")\n", "    plt.ylabel(\"y\")\n", "    plt.xlim((0, 1))\n", "    plt.ylim((-2, 2))\n", "    plt.legend(loc=\"best\")\n", "    plt.title(\"Degree {}\\nMSE = {:.2e}(+/- {:.2e})\".format(\n", "        degrees[i], -scores.mean(), scores.std()))\n", "plt.show()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}