{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "=========================================<br>\n", "Nested versus non-nested cross-validation<br>\n", "=========================================<br>\n", "This example compares non-nested and nested cross-validation strategies on a<br>\n", "classifier of the iris data set. Nested cross-validation (CV) is often used to<br>\n", "train a model in which hyperparameters also need to be optimized. Nested CV<br>\n", "estimates the generalization error of the underlying model and its<br>\n", "(hyper)parameter search. Choosing the parameters that maximize non-nested CV<br>\n", "biases the model to the dataset, yielding an overly-optimistic score.<br>\n", "Model selection without nested CV uses the same data to tune model parameters<br>\n", "and evaluate model performance. Information may thus \"leak\" into the model<br>\n", "and overfit the data. The magnitude of this effect is primarily dependent on<br>\n", "the size of the dataset and the stability of the model. See Cawley and Talbot<br>\n", "[1]_ for an analysis of these issues.<br>\n", "To avoid this problem, nested CV effectively uses a series of<br>\n", "train/validation/test set splits. In the inner loop (here executed by<br>\n", ":class:`GridSearchCV <sklearn.model_selection.GridSearchCV>`), the score is<br>\n", "approximately maximized by fitting a model to each training set, and then<br>\n", "directly maximized in selecting (hyper)parameters over the validation set. In<br>\n", "the outer loop (here in :func:`cross_val_score<br>\n", "<sklearn.model_selection.cross_val_score>`), generalization error is estimated<br>\n", "by averaging test set scores over several dataset splits.<br>\n", "The example below uses a support vector classifier with a non-linear kernel to<br>\n", "build a model with optimized hyperparameters by grid search. We compare the<br>\n", "performance of non-nested and nested CV strategies by taking the difference<br>\n", "between their scores.<br>\n", ".. topic:: See Also:<br>\n", "    - :ref:`cross_validation`<br>\n", "    - :ref:`grid_search`<br>\n", ".. topic:: References:<br>\n", "    .. [1] `Cawley, G.C.; Talbot, N.L.C. On over-fitting in model selection and<br>\n", "     subsequent selection bias in performance evaluation.<br>\n", "     J. Mach. Learn. Res 2010,11, 2079-2107.<br>\n", "     <http://jmlr.csail.mit.edu/papers/volume11/cawley10a/cawley10a.pdf>`_<br>\n", ""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.datasets import load_iris\n", "from matplotlib import pyplot as plt\n", "from sklearn.svm import SVC\n", "from sklearn.model_selection import GridSearchCV, cross_val_score, KFold\n", "import numpy as np"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(__doc__)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Number of random trials"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["NUM_TRIALS = 30"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Load the dataset"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["iris = load_iris()\n", "X_iris = iris.data\n", "y_iris = iris.target"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Set up possible values of parameters to optimize over"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["p_grid = {\"C\": [1, 10, 100],\n", "          \"gamma\": [.01, .1]}"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We will use a Support Vector Classifier with \"rbf\" kernel"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["svm = SVC(kernel=\"rbf\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Arrays to store scores"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["non_nested_scores = np.zeros(NUM_TRIALS)\n", "nested_scores = np.zeros(NUM_TRIALS)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Loop for each trial"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for i in range(NUM_TRIALS):\n\n", "    # Choose cross-validation techniques for the inner and outer loops,\n", "    # independently of the dataset.\n", "    # E.g \"GroupKFold\", \"LeaveOneOut\", \"LeaveOneGroupOut\", etc.\n", "    inner_cv = KFold(n_splits=4, shuffle=True, random_state=i)\n", "    outer_cv = KFold(n_splits=4, shuffle=True, random_state=i)\n\n", "    # Non_nested parameter search and scoring\n", "    clf = GridSearchCV(estimator=svm, param_grid=p_grid, cv=inner_cv)\n", "    clf.fit(X_iris, y_iris)\n", "    non_nested_scores[i] = clf.best_score_\n\n", "    # Nested CV with parameter optimization\n", "    nested_score = cross_val_score(clf, X=X_iris, y=y_iris, cv=outer_cv)\n", "    nested_scores[i] = nested_score.mean()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["score_difference = non_nested_scores - nested_scores"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"Average difference of {:6f} with std. dev. of {:6f}.\"\n", "      .format(score_difference.mean(), score_difference.std()))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Plot scores on each trial for nested and non-nested CV"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.figure()\n", "plt.subplot(211)\n", "non_nested_scores_line, = plt.plot(non_nested_scores, color='r')\n", "nested_line, = plt.plot(nested_scores, color='b')\n", "plt.ylabel(\"score\", fontsize=\"14\")\n", "plt.legend([non_nested_scores_line, nested_line],\n", "           [\"Non-Nested CV\", \"Nested CV\"],\n", "           bbox_to_anchor=(0, .4, .5, 0))\n", "plt.title(\"Non-Nested and Nested Cross Validation on Iris Dataset\",\n", "          x=.5, y=1.1, fontsize=\"15\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Plot bar chart of the difference."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.subplot(212)\n", "difference_plot = plt.bar(range(NUM_TRIALS), score_difference)\n", "plt.xlabel(\"Individual Trial #\")\n", "plt.legend([difference_plot],\n", "           [\"Non-Nested CV - Nested CV Score\"],\n", "           bbox_to_anchor=(0, 1, .8, 0))\n", "plt.ylabel(\"score difference\", fontsize=\"14\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.show()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}