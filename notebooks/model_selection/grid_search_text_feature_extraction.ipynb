{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "==========================================================<br>\n", "Sample pipeline for text feature extraction and evaluation<br>\n", "==========================================================<br>\n", "The dataset used in this example is the 20 newsgroups dataset which will be<br>\n", "automatically downloaded and then cached and reused for the document<br>\n", "classification example.<br>\n", "You can adjust the number of categories by giving their names to the dataset<br>\n", "loader or setting them to None to get the 20 of them.<br>\n", "Here is a sample output of a run on a quad-core machine::<br>\n", "  Loading 20 newsgroups dataset for categories:<br>\n", "  ['alt.atheism', 'talk.religion.misc']<br>\n", "  1427 documents<br>\n", "  2 categories<br>\n", "  Performing grid search...<br>\n", "  pipeline: ['vect', 'tfidf', 'clf']<br>\n", "  parameters:<br>\n", "  {'clf__alpha': (1.0000000000000001e-05, 9.9999999999999995e-07),<br>\n", "   'clf__max_iter': (10, 50, 80),<br>\n", "   'clf__penalty': ('l2', 'elasticnet'),<br>\n", "   'tfidf__use_idf': (True, False),<br>\n", "   'vect__max_n': (1, 2),<br>\n", "   'vect__max_df': (0.5, 0.75, 1.0),<br>\n", "   'vect__max_features': (None, 5000, 10000, 50000)}<br>\n", "  done in 1737.030s<br>\n", "  Best score: 0.940<br>\n", "  Best parameters set:<br>\n", "      clf__alpha: 9.9999999999999995e-07<br>\n", "      clf__max_iter: 50<br>\n", "      clf__penalty: 'elasticnet'<br>\n", "      tfidf__use_idf: True<br>\n", "      vect__max_n: 2<br>\n", "      vect__max_df: 0.75<br>\n", "      vect__max_features: 50000<br>\n", ""]}, {"cell_type": "markdown", "metadata": {}, "source": ["Author: Olivier Grisel <olivier.grisel@ensta.org><br>\n", "        Peter Prettenhofer <peter.prettenhofer@gmail.com><br>\n", "        Mathieu Blondel <mathieu@mblondel.org><br>\n", "License: BSD 3 clause"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from pprint import pprint\n", "from time import time\n", "import logging"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.datasets import fetch_20newsgroups\n", "from sklearn.feature_extraction.text import CountVectorizer\n", "from sklearn.feature_extraction.text import TfidfTransformer\n", "from sklearn.linear_model import SGDClassifier\n", "from sklearn.model_selection import GridSearchCV\n", "from sklearn.pipeline import Pipeline"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(__doc__)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Display progress logs on stdout"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["logging.basicConfig(level=logging.INFO,\n", "                    format='%(asctime)s %(levelname)s %(message)s')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#############################################################################<br>\n", "Load some categories from the training set"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["categories = [\n", "    'alt.atheism',\n", "    'talk.religion.misc',\n", "]\n", "# Uncomment the following to do the analysis on all the categories\n", "#categories = None"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"Loading 20 newsgroups dataset for categories:\")\n", "print(categories)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["data = fetch_20newsgroups(subset='train', categories=categories)\n", "print(\"%d documents\" % len(data.filenames))\n", "print(\"%d categories\" % len(data.target_names))\n", "print()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#############################################################################<br>\n", "Define a pipeline combining a text feature extractor with a simple<br>\n", "classifier"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["pipeline = Pipeline([\n", "    ('vect', CountVectorizer()),\n", "    ('tfidf', TfidfTransformer()),\n", "    ('clf', SGDClassifier()),\n", "])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["uncommenting more parameters will give better exploring power but will<br>\n", "increase processing time in a combinatorial way"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["parameters = {\n", "    'vect__max_df': (0.5, 0.75, 1.0),\n", "    # 'vect__max_features': (None, 5000, 10000, 50000),\n", "    'vect__ngram_range': ((1, 1), (1, 2)),  # unigrams or bigrams\n", "    # 'tfidf__use_idf': (True, False),\n", "    # 'tfidf__norm': ('l1', 'l2'),\n", "    'clf__max_iter': (20,),\n", "    'clf__alpha': (0.00001, 0.000001),\n", "    'clf__penalty': ('l2', 'elasticnet'),\n", "    # 'clf__max_iter': (10, 50, 80),\n", "}"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if __name__ == \"__main__\":\n", "    # multiprocessing requires the fork to happen in a __main__ protected\n", "    # block\n\n", "    # find the best parameters for both the feature extraction and the\n", "    # classifier\n", "    grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1)\n", "    print(\"Performing grid search...\")\n", "    print(\"pipeline:\", [name for name, _ in pipeline.steps])\n", "    print(\"parameters:\")\n", "    pprint(parameters)\n", "    t0 = time()\n", "    grid_search.fit(data.data, data.target)\n", "    print(\"done in %0.3fs\" % (time() - t0))\n", "    print()\n", "    print(\"Best score: %0.3f\" % grid_search.best_score_)\n", "    print(\"Best parameters set:\")\n", "    best_parameters = grid_search.best_estimator_.get_params()\n", "    for param_name in sorted(parameters.keys()):\n", "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}