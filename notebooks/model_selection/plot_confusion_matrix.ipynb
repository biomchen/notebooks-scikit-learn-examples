{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "================<br>\n", "Confusion matrix<br>\n", "================<br>\n", "Example of confusion matrix usage to evaluate the quality<br>\n", "of the output of a classifier on the iris data set. The<br>\n", "diagonal elements represent the number of points for which<br>\n", "the predicted label is equal to the true label, while<br>\n", "off-diagonal elements are those that are mislabeled by the<br>\n", "classifier. The higher the diagonal values of the confusion<br>\n", "matrix the better, indicating many correct predictions.<br>\n", "The figures show the confusion matrix with and without<br>\n", "normalization by class support size (number of elements<br>\n", "in each class). This kind of normalization can be<br>\n", "interesting in case of class imbalance to have a more<br>\n", "visual interpretation of which class is being misclassified.<br>\n", "Here the results are not as good as they could be as our<br>\n", "choice for the regularization parameter C was not the best.<br>\n", "In real life applications this parameter is usually chosen<br>\n", "using :ref:`grid_search`.<br>\n", ""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(__doc__)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "import matplotlib.pyplot as plt"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn import svm, datasets\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.metrics import plot_confusion_matrix"]}, {"cell_type": "markdown", "metadata": {}, "source": ["import some data to play with"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["iris = datasets.load_iris()\n", "X = iris.data\n", "y = iris.target\n", "class_names = iris.target_names"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Split the data into a training set and a test set"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Run classifier, using a model that is too regularized (C too low) to see<br>\n", "the impact on the results"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["classifier = svm.SVC(kernel='linear', C=0.01).fit(X_train, y_train)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["np.set_printoptions(precision=2)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Plot non-normalized confusion matrix"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["titles_options = [(\"Confusion matrix, without normalization\", None),\n", "                  (\"Normalized confusion matrix\", 'true')]\n", "for title, normalize in titles_options:\n", "    disp = plot_confusion_matrix(classifier, X_test, y_test,\n", "                                 display_labels=class_names,\n", "                                 cmap=plt.cm.Blues,\n", "                                 normalize=normalize)\n", "    disp.ax_.set_title(title)\n", "    print(title)\n", "    print(disp.confusion_matrix)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.show()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}