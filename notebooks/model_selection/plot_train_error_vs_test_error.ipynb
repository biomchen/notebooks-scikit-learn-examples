{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "=========================<br>\n", "Train error vs Test error<br>\n", "=========================<br>\n", "Illustration of how the performance of an estimator on unseen data (test data)<br>\n", "is not the same as the performance on training data. As the regularization<br>\n", "increases the performance on train decreases while the performance on test<br>\n", "is optimal within a range of values of the regularization parameter.<br>\n", "The example with an Elastic-Net regression model and the performance is<br>\n", "measured using the explained variance a.k.a. R^2.<br>\n", ""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(__doc__)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Author: Alexandre Gramfort <alexandre.gramfort@inria.fr><br>\n", "License: BSD 3 clause"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "from sklearn import linear_model"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#############################################################################<br>\n", "Generate sample data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["n_samples_train, n_samples_test, n_features = 75, 150, 500\n", "np.random.seed(0)\n", "coef = np.random.randn(n_features)\n", "coef[50:] = 0.0  # only the top 10 features are impacting the model\n", "X = np.random.randn(n_samples_train + n_samples_test, n_features)\n", "y = np.dot(X, coef)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Split train and test data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X_train, X_test = X[:n_samples_train], X[n_samples_train:]\n", "y_train, y_test = y[:n_samples_train], y[n_samples_train:]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#############################################################################<br>\n", "Compute train and test errors"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["alphas = np.logspace(-5, 1, 60)\n", "enet = linear_model.ElasticNet(l1_ratio=0.7, max_iter=10000)\n", "train_errors = list()\n", "test_errors = list()\n", "for alpha in alphas:\n", "    enet.set_params(alpha=alpha)\n", "    enet.fit(X_train, y_train)\n", "    train_errors.append(enet.score(X_train, y_train))\n", "    test_errors.append(enet.score(X_test, y_test))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["i_alpha_optim = np.argmax(test_errors)\n", "alpha_optim = alphas[i_alpha_optim]\n", "print(\"Optimal regularization parameter : %s\" % alpha_optim)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Estimate the coef_ on full data with optimal regularization parameter"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["enet.set_params(alpha=alpha_optim)\n", "coef_ = enet.fit(X, y).coef_"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#############################################################################<br>\n", "Plot results functions"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import matplotlib.pyplot as plt\n", "plt.subplot(2, 1, 1)\n", "plt.semilogx(alphas, train_errors, label='Train')\n", "plt.semilogx(alphas, test_errors, label='Test')\n", "plt.vlines(alpha_optim, plt.ylim()[0], np.max(test_errors), color='k',\n", "           linewidth=3, label='Optimum on test')\n", "plt.legend(loc='lower left')\n", "plt.ylim([0, 1.2])\n", "plt.xlabel('Regularization parameter')\n", "plt.ylabel('Performance')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Show estimated coef_ vs true coef"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.subplot(2, 1, 2)\n", "plt.plot(coef, label='True coef')\n", "plt.plot(coef_, label='Estimated coef')\n", "plt.legend()\n", "plt.subplots_adjust(0.09, 0.04, 0.94, 0.94, 0.26, 0.26)\n", "plt.show()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}