{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["#!/usr/bin/python\n", "# -*- coding: utf-8 -*-"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "=========================================================<br>\n", "Ordinary Least Squares and Ridge Regression Variance<br>\n", "=========================================================<br>\n", "Due to the few points in each dimension and the straight<br>\n", "line that linear regression uses to follow these points<br>\n", "as well as it can, noise on the observations will cause<br>\n", "great variance as shown in the first plot. Every line's slope<br>\n", "can vary quite a bit for each prediction due to the noise<br>\n", "induced in the observations.<br>\n", "Ridge regression is basically minimizing a penalised version<br>\n", "of the least-squared function. The penalising `shrinks` the<br>\n", "value of the regression coefficients.<br>\n", "Despite the few data points in each dimension, the slope<br>\n", "of the prediction is much more stable and the variance<br>\n", "in the line itself is greatly reduced, in comparison to that<br>\n", "of the standard linear regression<br>\n", ""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(__doc__)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Code source: Ga\u00ebl Varoquaux<br>\n", "Modified for documentation by Jaques Grobler<br>\n", "License: BSD 3 clause"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "import matplotlib.pyplot as plt"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn import linear_model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X_train = np.c_[.5, 1].T\n", "y_train = [.5, 1]\n", "X_test = np.c_[0, 2].T"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["np.random.seed(0)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["classifiers = dict(ols=linear_model.LinearRegression(),\n", "                   ridge=linear_model.Ridge(alpha=.1))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for name, clf in classifiers.items():\n", "    fig, ax = plt.subplots(figsize=(4, 3))\n", "    for _ in range(6):\n", "        this_X = .1 * np.random.normal(size=(2, 1)) + X_train\n", "        clf.fit(this_X, y_train)\n", "        ax.plot(X_test, clf.predict(X_test), color='gray')\n", "        ax.scatter(this_X, y_train, s=3, c='gray', marker='o', zorder=10)\n", "    clf.fit(X_train, y_train)\n", "    ax.plot(X_test, clf.predict(X_test), linewidth=2, color='blue')\n", "    ax.scatter(X_train, y_train, s=30, c='red', marker='+', zorder=10)\n", "    ax.set_title(name)\n", "    ax.set_xlim(0, 2)\n", "    ax.set_ylim((0, 1.6))\n", "    ax.set_xlabel('X')\n", "    ax.set_ylabel('y')\n", "    fig.tight_layout()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.show()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}