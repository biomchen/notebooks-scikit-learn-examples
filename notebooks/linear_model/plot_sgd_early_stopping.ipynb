{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "=============================================<br>\n", "Early stopping of Stochastic Gradient Descent<br>\n", "=============================================<br>\n", "Stochastic Gradient Descent is an optimization technique which minimizes a loss<br>\n", "function in a stochastic fashion, performing a gradient descent step sample by<br>\n", "sample. In particular, it is a very efficient method to fit linear models.<br>\n", "As a stochastic method, the loss function is not necessarily decreasing at each<br>\n", "iteration, and convergence is only guaranteed in expectation. For this reason,<br>\n", "monitoring the convergence on the loss function can be difficult.<br>\n", "Another approach is to monitor convergence on a validation score. In this case,<br>\n", "the input data is split into a training set and a validation set. The model is<br>\n", "then fitted on the training set and the stopping criterion is based on the<br>\n", "prediction score computed on the validation set. This enables us to find the<br>\n", "least number of iterations which is sufficient to build a model that<br>\n", "generalizes well to unseen data and reduces the chance of over-fitting the<br>\n", "training data.<br>\n", "This early stopping strategy is activated if ``early_stopping=True``; otherwise<br>\n", "the stopping criterion only uses the training loss on the entire input data. To<br>\n", "better control the early stopping strategy, we can specify a parameter<br>\n", "``validation_fraction`` which set the fraction of the input dataset that we<br>\n", "keep aside to compute the validation score. The optimization will continue<br>\n", "until the validation score did not improve by at least ``tol`` during the last<br>\n", "``n_iter_no_change`` iterations. The actual number of iterations is available<br>\n", "at the attribute ``n_iter_``.<br>\n", "This example illustrates how the early stopping can used in the<br>\n", ":class:`sklearn.linear_model.SGDClassifier` model to achieve almost the same<br>\n", "accuracy as compared to a model built without early stopping. This can<br>\n", "significantly reduce training time. Note that scores differ between the<br>\n", "stopping criteria even from early iterations because some of the training data<br>\n", "is held out with the validation stopping criterion.<br>\n", "<br>\n", "Authors: Tom Dupre la Tour<br>\n", "<br>\n", "License: BSD 3 clause"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import time\n", "import sys"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import pandas as pd\n", "import numpy as np\n", "import matplotlib.pyplot as plt"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn import linear_model\n", "from sklearn.datasets import fetch_openml\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.utils._testing import ignore_warnings\n", "from sklearn.exceptions import ConvergenceWarning\n", "from sklearn.utils import shuffle"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(__doc__)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def load_mnist(n_samples=None, class_0='0', class_1='8'):\n", "    \"\"\"Load MNIST, select two classes, shuffle and return only n_samples.\"\"\"\n", "    # Load data from http://openml.org/d/554\n", "    mnist = fetch_openml('mnist_784', version=1)\n\n", "    # take only two classes for binary classification\n", "    mask = np.logical_or(mnist.target == class_0, mnist.target == class_1)\n", "    X, y = shuffle(mnist.data[mask], mnist.target[mask], random_state=42)\n", "    if n_samples is not None:\n", "        X, y = X[:n_samples], y[:n_samples]\n", "    return X, y"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["@ignore_warnings(category=ConvergenceWarning)\n", "def fit_and_score(estimator, max_iter, X_train, X_test, y_train, y_test):\n", "    \"\"\"Fit the estimator on the train set and score it on both sets\"\"\"\n", "    estimator.set_params(max_iter=max_iter)\n", "    estimator.set_params(random_state=0)\n", "    start = time.time()\n", "    estimator.fit(X_train, y_train)\n", "    fit_time = time.time() - start\n", "    n_iter = estimator.n_iter_\n", "    train_score = estimator.score(X_train, y_train)\n", "    test_score = estimator.score(X_test, y_test)\n", "    return fit_time, n_iter, train_score, test_score"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Define the estimators to compare"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["estimator_dict = {\n", "    'No stopping criterion':\n", "    linear_model.SGDClassifier(n_iter_no_change=3),\n", "    'Training loss':\n", "    linear_model.SGDClassifier(early_stopping=False, n_iter_no_change=3,\n", "                               tol=0.1),\n", "    'Validation score':\n", "    linear_model.SGDClassifier(early_stopping=True, n_iter_no_change=3,\n", "                               tol=0.0001, validation_fraction=0.2)\n", "}"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Load the dataset"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X, y = load_mnist(n_samples=10000)\n", "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5,\n", "                                                    random_state=0)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["results = []\n", "for estimator_name, estimator in estimator_dict.items():\n", "    print(estimator_name + ': ', end='')\n", "    for max_iter in range(1, 50):\n", "        print('.', end='')\n", "        sys.stdout.flush()\n", "        fit_time, n_iter, train_score, test_score = fit_and_score(\n", "            estimator, max_iter, X_train, X_test, y_train, y_test)\n", "        results.append((estimator_name, max_iter, fit_time, n_iter,\n", "                        train_score, test_score))\n", "    print('')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Transform the results in a pandas dataframe for easy plotting"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["columns = [\n", "    'Stopping criterion', 'max_iter', 'Fit time (sec)', 'n_iter_',\n", "    'Train score', 'Test score'\n", "]\n", "results_df = pd.DataFrame(results, columns=columns)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Define what to plot (x_axis, y_axis)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["lines = 'Stopping criterion'\n", "plot_list = [\n", "    ('max_iter', 'Train score'),\n", "    ('max_iter', 'Test score'),\n", "    ('max_iter', 'n_iter_'),\n", "    ('max_iter', 'Fit time (sec)'),\n", "]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["nrows = 2\n", "ncols = int(np.ceil(len(plot_list) / 2.))\n", "fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(6 * ncols,\n", "                                                            4 * nrows))\n", "axes[0, 0].get_shared_y_axes().join(axes[0, 0], axes[0, 1])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for ax, (x_axis, y_axis) in zip(axes.ravel(), plot_list):\n", "    for criterion, group_df in results_df.groupby(lines):\n", "        group_df.plot(x=x_axis, y=y_axis, label=criterion, ax=ax)\n", "    ax.set_title(y_axis)\n", "    ax.legend(title=lines)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fig.tight_layout()\n", "plt.show()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}