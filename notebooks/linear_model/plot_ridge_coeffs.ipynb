{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "==============================================================<br>\n", "Plot Ridge coefficients as a function of the L2 regularization<br>\n", "==============================================================<br>\n", ".. currentmodule:: sklearn.linear_model<br>\n", ":class:`Ridge` Regression is the estimator used in this example.<br>\n", "Each color in the left plot represents one different dimension of the<br>\n", "coefficient vector, and this is displayed as a function of the<br>\n", "regularization parameter. The right plot shows how exact the solution<br>\n", "is. This example illustrates how a well defined solution is<br>\n", "found by Ridge regression and how regularization affects the<br>\n", "coefficients and their values. The plot on the right shows how<br>\n", "the difference of the coefficients from the estimator changes<br>\n", "as a function of regularization.<br>\n", "In this example the dependent variable Y is set as a function<br>\n", "of the input features: y = X*w + c. The coefficient vector w is<br>\n", "randomly sampled from a normal distribution, whereas the bias term c is<br>\n", "set to a constant.<br>\n", "As alpha tends toward zero the coefficients found by Ridge<br>\n", "regression stabilize towards the randomly sampled vector w.<br>\n", "For big alpha (strong regularisation) the coefficients<br>\n", "are smaller (eventually converging at 0) leading to a<br>\n", "simpler and biased solution.<br>\n", "These dependencies can be observed on the left plot.<br>\n", "The right plot shows the mean squared error between the<br>\n", "coefficients found by the model and the chosen vector w.<br>\n", "Less regularised models retrieve the exact<br>\n", "coefficients (error is equal to 0), stronger regularised<br>\n", "models increase the error.<br>\n", "Please note that in this example the data is non-noisy, hence<br>\n", "it is possible to extract the exact coefficients.<br>\n", ""]}, {"cell_type": "markdown", "metadata": {}, "source": ["Author: Kornel Kielczewski -- <kornel.k@plusnet.pl>"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(__doc__)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import matplotlib.pyplot as plt\n", "import numpy as np"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.datasets import make_regression\n", "from sklearn.linear_model import Ridge\n", "from sklearn.metrics import mean_squared_error"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["clf = Ridge()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X, y, w = make_regression(n_samples=10, n_features=10, coef=True,\n", "                          random_state=1, bias=3.5)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["coefs = []\n", "errors = []"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["alphas = np.logspace(-6, 6, 200)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Train the model with different regularisation strengths"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for a in alphas:\n", "    clf.set_params(alpha=a)\n", "    clf.fit(X, y)\n", "    coefs.append(clf.coef_)\n", "    errors.append(mean_squared_error(clf.coef_, w))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Display results"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(20, 6))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.subplot(121)\n", "ax = plt.gca()\n", "ax.plot(alphas, coefs)\n", "ax.set_xscale('log')\n", "plt.xlabel('alpha')\n", "plt.ylabel('weights')\n", "plt.title('Ridge coefficients as a function of the regularization')\n", "plt.axis('tight')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.subplot(122)\n", "ax = plt.gca()\n", "ax.plot(alphas, errors)\n", "ax.set_xscale('log')\n", "plt.xlabel('alpha')\n", "plt.ylabel('error')\n", "plt.title('Coefficient error as a function of the regularization')\n", "plt.axis('tight')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.show()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}