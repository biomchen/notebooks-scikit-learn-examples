{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "===================================================<br>\n", "Lasso model selection: Cross-Validation / AIC / BIC<br>\n", "===================================================<br>\n", "Use the Akaike information criterion (AIC), the Bayes Information<br>\n", "criterion (BIC) and cross-validation to select an optimal value<br>\n", "of the regularization parameter alpha of the :ref:`lasso` estimator.<br>\n", "Results obtained with LassoLarsIC are based on AIC/BIC criteria.<br>\n", "Information-criterion based model selection is very fast, but it<br>\n", "relies on a proper estimation of degrees of freedom, are<br>\n", "derived for large samples (asymptotic results) and assume the model<br>\n", "is correct, i.e. that the data are actually generated by this model.<br>\n", "They also tend to break when the problem is badly conditioned<br>\n", "(more features than samples).<br>\n", "For cross-validation, we use 20-fold with 2 algorithms to compute the<br>\n", "Lasso path: coordinate descent, as implemented by the LassoCV class, and<br>\n", "Lars (least angle regression) as implemented by the LassoLarsCV class.<br>\n", "Both algorithms give roughly the same results. They differ with regards<br>\n", "to their execution speed and sources of numerical errors.<br>\n", "Lars computes a path solution only for each kink in the path. As a<br>\n", "result, it is very efficient when there are only of few kinks, which is<br>\n", "the case if there are few features or samples. Also, it is able to<br>\n", "compute the full path without setting any meta parameter. On the<br>\n", "opposite, coordinate descent compute the path points on a pre-specified<br>\n", "grid (here we use the default). Thus it is more efficient if the number<br>\n", "of grid points is smaller than the number of kinks in the path. Such a<br>\n", "strategy can be interesting if the number of features is really large<br>\n", "and there are enough samples to select a large amount. In terms of<br>\n", "numerical errors, for heavily correlated variables, Lars will accumulate<br>\n", "more errors, while the coordinate descent algorithm will only sample the<br>\n", "path on a grid.<br>\n", "Note how the optimal value of alpha varies for each fold. This<br>\n", "illustrates why nested-cross validation is necessary when trying to<br>\n", "evaluate the performance of a method for which a parameter is chosen by<br>\n", "cross-validation: this choice of parameter may not be optimal for unseen<br>\n", "data.<br>\n", ""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(__doc__)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Author: Olivier Grisel, Gael Varoquaux, Alexandre Gramfort<br>\n", "License: BSD 3 clause"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import time"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "import matplotlib.pyplot as plt"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.linear_model import LassoCV, LassoLarsCV, LassoLarsIC\n", "from sklearn import datasets"]}, {"cell_type": "markdown", "metadata": {}, "source": ["This is to avoid division by zero while doing np.log10"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["EPSILON = 1e-4"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X, y = datasets.load_diabetes(return_X_y=True)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["rng = np.random.RandomState(42)\n", "X = np.c_[X, rng.randn(X.shape[0], 14)]  # add some bad features"]}, {"cell_type": "markdown", "metadata": {}, "source": ["normalize data as done by Lars to allow for comparison"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X /= np.sqrt(np.sum(X ** 2, axis=0))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#############################################################################<br>\n", "LassoLarsIC: least angle regression with BIC/AIC criterion"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model_bic = LassoLarsIC(criterion='bic')\n", "t1 = time.time()\n", "model_bic.fit(X, y)\n", "t_bic = time.time() - t1\n", "alpha_bic_ = model_bic.alpha_"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model_aic = LassoLarsIC(criterion='aic')\n", "model_aic.fit(X, y)\n", "alpha_aic_ = model_aic.alpha_"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def plot_ic_criterion(model, name, color):\n", "    alpha_ = model.alpha_ + EPSILON\n", "    alphas_ = model.alphas_ + EPSILON\n", "    criterion_ = model.criterion_\n", "    plt.plot(-np.log10(alphas_), criterion_, '--', color=color,\n", "             linewidth=3, label='%s criterion' % name)\n", "    plt.axvline(-np.log10(alpha_), color=color, linewidth=3,\n", "                label='alpha: %s estimate' % name)\n", "    plt.xlabel('-log(alpha)')\n", "    plt.ylabel('criterion')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.figure()\n", "plot_ic_criterion(model_aic, 'AIC', 'b')\n", "plot_ic_criterion(model_bic, 'BIC', 'r')\n", "plt.legend()\n", "plt.title('Information-criterion for model selection (training time %.3fs)'\n", "          % t_bic)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#############################################################################<br>\n", "LassoCV: coordinate descent"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Compute paths"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"Computing regularization path using the coordinate descent lasso...\")\n", "t1 = time.time()\n", "model = LassoCV(cv=20).fit(X, y)\n", "t_lasso_cv = time.time() - t1"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Display results"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["m_log_alphas = -np.log10(model.alphas_ + EPSILON)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.figure()\n", "ymin, ymax = 2300, 3800\n", "plt.plot(m_log_alphas, model.mse_path_, ':')\n", "plt.plot(m_log_alphas, model.mse_path_.mean(axis=-1), 'k',\n", "         label='Average across the folds', linewidth=2)\n", "plt.axvline(-np.log10(model.alpha_ + EPSILON), linestyle='--', color='k',\n", "            label='alpha: CV estimate')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.legend()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.xlabel('-log(alpha)')\n", "plt.ylabel('Mean square error')\n", "plt.title('Mean square error on each fold: coordinate descent '\n", "          '(train time: %.2fs)' % t_lasso_cv)\n", "plt.axis('tight')\n", "plt.ylim(ymin, ymax)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#############################################################################<br>\n", "LassoLarsCV: least angle regression"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Compute paths"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"Computing regularization path using the Lars lasso...\")\n", "t1 = time.time()\n", "model = LassoLarsCV(cv=20).fit(X, y)\n", "t_lasso_lars_cv = time.time() - t1"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Display results"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["m_log_alphas = -np.log10(model.cv_alphas_ + EPSILON)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.figure()\n", "plt.plot(m_log_alphas, model.mse_path_, ':')\n", "plt.plot(m_log_alphas, model.mse_path_.mean(axis=-1), 'k',\n", "         label='Average across the folds', linewidth=2)\n", "plt.axvline(-np.log10(model.alpha_), linestyle='--', color='k',\n", "            label='alpha CV')\n", "plt.legend()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.xlabel('-log(alpha)')\n", "plt.ylabel('Mean square error')\n", "plt.title('Mean square error on each fold: Lars (train time: %.2fs)'\n", "          % t_lasso_lars_cv)\n", "plt.axis('tight')\n", "plt.ylim(ymin, ymax)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.show()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}