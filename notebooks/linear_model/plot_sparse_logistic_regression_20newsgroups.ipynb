{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "====================================================<br>\n", "Multiclass sparse logistic regression on 20newgroups<br>\n", "====================================================<br>\n", "Comparison of multinomial logistic L1 vs one-versus-rest L1 logistic regression<br>\n", "to classify documents from the newgroups20 dataset. Multinomial logistic<br>\n", "regression yields more accurate results and is faster to train on the larger<br>\n", "scale dataset.<br>\n", "Here we use the l1 sparsity that trims the weights of not informative<br>\n", "features to zero. This is good if the goal is to extract the strongly<br>\n", "discriminative vocabulary of each class. If the goal is to get the best<br>\n", "predictive accuracy, it is better to use the non sparsity-inducing l2 penalty<br>\n", "instead.<br>\n", "A more traditional (and possibly better) way to predict on a sparse subset of<br>\n", "input features would be to use univariate feature selection followed by a<br>\n", "traditional (l2-penalised) logistic regression model.<br>\n", ""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import timeit\n", "import warnings"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import matplotlib.pyplot as plt\n", "import numpy as np"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.datasets import fetch_20newsgroups_vectorized\n", "from sklearn.linear_model import LogisticRegression\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.exceptions import ConvergenceWarning"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(__doc__)\n", "# Author: Arthur Mensch"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["warnings.filterwarnings(\"ignore\", category=ConvergenceWarning,\n", "                        module=\"sklearn\")\n", "t0 = timeit.default_timer()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We use SAGA solver"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["solver = 'saga'"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Turn down for faster run time"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["n_samples = 10000"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X, y = fetch_20newsgroups_vectorized('all', return_X_y=True)\n", "X = X[:n_samples]\n", "y = y[:n_samples]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X_train, X_test, y_train, y_test = train_test_split(X, y,\n", "                                                    random_state=42,\n", "                                                    stratify=y,\n", "                                                    test_size=0.1)\n", "train_samples, n_features = X_train.shape\n", "n_classes = np.unique(y).shape[0]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print('Dataset 20newsgroup, train_samples=%i, n_features=%i, n_classes=%i'\n", "      % (train_samples, n_features, n_classes))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["models = {'ovr': {'name': 'One versus Rest', 'iters': [1, 2, 4]},\n", "          'multinomial': {'name': 'Multinomial', 'iters': [1, 3, 7]}}"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for model in models:\n", "    # Add initial chance-level values for plotting purpose\n", "    accuracies = [1 / n_classes]\n", "    times = [0]\n", "    densities = [1]\n", "    model_params = models[model]\n\n", "    # Small number of epochs for fast runtime\n", "    for this_max_iter in model_params['iters']:\n", "        print('[model=%s, solver=%s] Number of epochs: %s' %\n", "              (model_params['name'], solver, this_max_iter))\n", "        lr = LogisticRegression(solver=solver,\n", "                                multi_class=model,\n", "                                penalty='l1',\n", "                                max_iter=this_max_iter,\n", "                                random_state=42,\n", "                                )\n", "        t1 = timeit.default_timer()\n", "        lr.fit(X_train, y_train)\n", "        train_time = timeit.default_timer() - t1\n", "        y_pred = lr.predict(X_test)\n", "        accuracy = np.sum(y_pred == y_test) / y_test.shape[0]\n", "        density = np.mean(lr.coef_ != 0, axis=1) * 100\n", "        accuracies.append(accuracy)\n", "        densities.append(density)\n", "        times.append(train_time)\n", "    models[model]['times'] = times\n", "    models[model]['densities'] = densities\n", "    models[model]['accuracies'] = accuracies\n", "    print('Test accuracy for model %s: %.4f' % (model, accuracies[-1]))\n", "    print('%% non-zero coefficients for model %s, '\n", "          'per class:\\n %s' % (model, densities[-1]))\n", "    print('Run time (%i epochs) for model %s:'\n", "          '%.2f' % (model_params['iters'][-1], model, times[-1]))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fig = plt.figure()\n", "ax = fig.add_subplot(111)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for model in models:\n", "    name = models[model]['name']\n", "    times = models[model]['times']\n", "    accuracies = models[model]['accuracies']\n", "    ax.plot(times, accuracies, marker='o',\n", "            label='Model: %s' % name)\n", "    ax.set_xlabel('Train time (s)')\n", "    ax.set_ylabel('Test accuracy')\n", "ax.legend()\n", "fig.suptitle('Multinomial vs One-vs-Rest Logistic L1\\n'\n", "             'Dataset %s' % '20newsgroups')\n", "fig.tight_layout()\n", "fig.subplots_adjust(top=0.85)\n", "run_time = timeit.default_timer() - t0\n", "print('Example run in %.3f s' % run_time)\n", "plt.show()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}