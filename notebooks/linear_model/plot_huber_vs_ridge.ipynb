{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "=======================================================<br>\n", "HuberRegressor vs Ridge on dataset with strong outliers<br>\n", "=======================================================<br>\n", "Fit Ridge and HuberRegressor on a dataset with outliers.<br>\n", "The example shows that the predictions in ridge are strongly influenced<br>\n", "by the outliers present in the dataset. The Huber regressor is less<br>\n", "influenced by the outliers since the model uses the linear loss for these.<br>\n", "As the parameter epsilon is increased for the Huber regressor, the decision<br>\n", "function approaches that of the ridge.<br>\n", ""]}, {"cell_type": "markdown", "metadata": {}, "source": ["Authors: Manoj Kumar mks542@nyu.edu<br>\n", "License: BSD 3 clause"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(__doc__)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "import matplotlib.pyplot as plt"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.datasets import make_regression\n", "from sklearn.linear_model import HuberRegressor, Ridge"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Generate toy data."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["rng = np.random.RandomState(0)\n", "X, y = make_regression(n_samples=20, n_features=1, random_state=0, noise=4.0,\n", "                       bias=100.0)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Add four strong outliers to the dataset."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X_outliers = rng.normal(0, 0.5, size=(4, 1))\n", "y_outliers = rng.normal(0, 2.0, size=4)\n", "X_outliers[:2, :] += X.max() + X.mean() / 4.\n", "X_outliers[2:, :] += X.min() - X.mean() / 4.\n", "y_outliers[:2] += y.min() - y.mean() / 4.\n", "y_outliers[2:] += y.max() + y.mean() / 4.\n", "X = np.vstack((X, X_outliers))\n", "y = np.concatenate((y, y_outliers))\n", "plt.plot(X, y, 'b.')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Fit the huber regressor over a series of epsilon values."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["colors = ['r-', 'b-', 'y-', 'm-']"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["x = np.linspace(X.min(), X.max(), 7)\n", "epsilon_values = [1.35, 1.5, 1.75, 1.9]\n", "for k, epsilon in enumerate(epsilon_values):\n", "    huber = HuberRegressor(alpha=0.0, epsilon=epsilon)\n", "    huber.fit(X, y)\n", "    coef_ = huber.coef_ * x + huber.intercept_\n", "    plt.plot(x, coef_, colors[k], label=\"huber loss, %s\" % epsilon)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Fit a ridge regressor to compare it to huber regressor."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["ridge = Ridge(alpha=0.0, random_state=0, normalize=True)\n", "ridge.fit(X, y)\n", "coef_ridge = ridge.coef_\n", "coef_ = ridge.coef_ * x + ridge.intercept_\n", "plt.plot(x, coef_, 'g-', label=\"ridge regression\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.title(\"Comparison of HuberRegressor vs Ridge\")\n", "plt.xlabel(\"X\")\n", "plt.ylabel(\"y\")\n", "plt.legend(loc=0)\n", "plt.show()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}