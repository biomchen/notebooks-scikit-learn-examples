{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "========================================<br>\n", "Comparison of Calibration of Classifiers<br>\n", "========================================<br>\n", "Well calibrated classifiers are probabilistic classifiers for which the output<br>\n", "of the predict_proba method can be directly interpreted as a confidence level.<br>\n", "For instance a well calibrated (binary) classifier should classify the samples<br>\n", "such that among the samples to which it gave a predict_proba value close to<br>\n", "0.8, approx. 80% actually belong to the positive class.<br>\n", "LogisticRegression returns well calibrated predictions as it directly<br>\n", "optimizes log-loss. In contrast, the other methods return biased probabilities,<br>\n", "with different biases per method:<br>\n", "* GaussianNaiveBayes tends to push probabilities to 0 or 1 (note the counts in<br>\n", "  the histograms). This is mainly because it makes the assumption that features<br>\n", "  are conditionally independent given the class, which is not the case in this<br>\n", "  dataset which contains 2 redundant features.<br>\n", "* RandomForestClassifier shows the opposite behavior: the histograms show<br>\n", "  peaks at approx. 0.2 and 0.9 probability, while probabilities close to 0 or 1<br>\n", "  are very rare. An explanation for this is given by Niculescu-Mizil and Caruana<br>\n", "  [1]_: \"Methods such as bagging and random forests that average predictions<br>\n", "  from a base set of models can have difficulty making predictions near 0 and 1<br>\n", "  because variance in the underlying base models will bias predictions that<br>\n", "  should be near zero or one away from these values. Because predictions are<br>\n", "  restricted to the interval [0,1], errors caused by variance tend to be one-<br>\n", "  sided near zero and one. For example, if a model should predict p = 0 for a<br>\n", "  case, the only way bagging can achieve this is if all bagged trees predict<br>\n", "  zero. If we add noise to the trees that bagging is averaging over, this noise<br>\n", "  will cause some trees to predict values larger than 0 for this case, thus<br>\n", "  moving the average prediction of the bagged ensemble away from 0. We observe<br>\n", "  this effect most strongly with random forests because the base-level trees<br>\n", "  trained with random forests have relatively high variance due to feature<br>\n", "  subsetting.\" As a result, the calibration curve shows a characteristic<br>\n", "  sigmoid shape, indicating that the classifier could trust its \"intuition\"<br>\n", "  more and return probabilities closer to 0 or 1 typically.<br>\n", "* Support Vector Classification (SVC) shows an even more sigmoid curve as<br>\n", "  the  RandomForestClassifier, which is typical for maximum-margin methods<br>\n", "  (compare Niculescu-Mizil and Caruana [1]_), which focus on hard samples<br>\n", "  that are close to the decision boundary (the support vectors).<br>\n", ".. topic:: References:<br>\n", "    .. [1] Predicting Good Probabilities with Supervised Learning,<br>\n", "          A. Niculescu-Mizil & R. Caruana, ICML 2005<br>\n", ""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(__doc__)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Author: Jan Hendrik Metzen <jhm@informatik.uni-bremen.de><br>\n", "License: BSD Style."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "np.random.seed(0)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import matplotlib.pyplot as plt"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn import datasets\n", "from sklearn.naive_bayes import GaussianNB\n", "from sklearn.linear_model import LogisticRegression\n", "from sklearn.ensemble import RandomForestClassifier\n", "from sklearn.svm import LinearSVC\n", "from sklearn.calibration import calibration_curve"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X, y = datasets.make_classification(n_samples=100000, n_features=20,\n", "                                    n_informative=2, n_redundant=2)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["train_samples = 100  # Samples used for training the models"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X_train = X[:train_samples]\n", "X_test = X[train_samples:]\n", "y_train = y[:train_samples]\n", "y_test = y[train_samples:]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Create classifiers"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["lr = LogisticRegression()\n", "gnb = GaussianNB()\n", "svc = LinearSVC(C=1.0)\n", "rfc = RandomForestClassifier()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#############################################################################<br>\n", "Plot calibration plots"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(10, 10))\n", "ax1 = plt.subplot2grid((3, 1), (0, 0), rowspan=2)\n", "ax2 = plt.subplot2grid((3, 1), (2, 0))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["ax1.plot([0, 1], [0, 1], \"k:\", label=\"Perfectly calibrated\")\n", "for clf, name in [(lr, 'Logistic'),\n", "                  (gnb, 'Naive Bayes'),\n", "                  (svc, 'Support Vector Classification'),\n", "                  (rfc, 'Random Forest')]:\n", "    clf.fit(X_train, y_train)\n", "    if hasattr(clf, \"predict_proba\"):\n", "        prob_pos = clf.predict_proba(X_test)[:, 1]\n", "    else:  # use decision function\n", "        prob_pos = clf.decision_function(X_test)\n", "        prob_pos = \\\n", "            (prob_pos - prob_pos.min()) / (prob_pos.max() - prob_pos.min())\n", "    fraction_of_positives, mean_predicted_value = \\\n", "        calibration_curve(y_test, prob_pos, n_bins=10)\n", "    ax1.plot(mean_predicted_value, fraction_of_positives, \"s-\",\n", "             label=\"%s\" % (name, ))\n", "    ax2.hist(prob_pos, range=(0, 1), bins=10, label=name,\n", "             histtype=\"step\", lw=2)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["ax1.set_ylabel(\"Fraction of positives\")\n", "ax1.set_ylim([-0.05, 1.05])\n", "ax1.legend(loc=\"lower right\")\n", "ax1.set_title('Calibration plots  (reliability curve)')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["ax2.set_xlabel(\"Mean predicted value\")\n", "ax2.set_ylabel(\"Count\")\n", "ax2.legend(loc=\"upper center\", ncol=2)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.tight_layout()\n", "plt.show()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}