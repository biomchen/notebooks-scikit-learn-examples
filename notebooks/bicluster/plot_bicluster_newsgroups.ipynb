{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "================================================================<br>\n", "Biclustering documents with the Spectral Co-clustering algorithm<br>\n", "================================================================<br>\n", "This example demonstrates the Spectral Co-clustering algorithm on the<br>\n", "twenty newsgroups dataset. The 'comp.os.ms-windows.misc' category is<br>\n", "excluded because it contains many posts containing nothing but data.<br>\n", "The TF-IDF vectorized posts form a word frequency matrix, which is<br>\n", "then biclustered using Dhillon's Spectral Co-Clustering algorithm. The<br>\n", "resulting document-word biclusters indicate subsets words used more<br>\n", "often in those subsets documents.<br>\n", "For a few of the best biclusters, its most common document categories<br>\n", "and its ten most important words get printed. The best biclusters are<br>\n", "determined by their normalized cut. The best words are determined by<br>\n", "comparing their sums inside and outside the bicluster.<br>\n", "For comparison, the documents are also clustered using<br>\n", "MiniBatchKMeans. The document clusters derived from the biclusters<br>\n", "achieve a better V-measure than clusters found by MiniBatchKMeans.<br>\n", ""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from collections import defaultdict\n", "import operator\n", "from time import time"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.cluster import SpectralCoclustering\n", "from sklearn.cluster import MiniBatchKMeans\n", "from sklearn.datasets import fetch_20newsgroups\n", "from sklearn.feature_extraction.text import TfidfVectorizer\n", "from sklearn.metrics.cluster import v_measure_score"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(__doc__)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def number_normalizer(tokens):\n", "    \"\"\" Map all numeric tokens to a placeholder.\n", "    For many applications, tokens that begin with a number are not directly\n", "    useful, but the fact that such a token exists can be relevant.  By applying\n", "    this form of dimensionality reduction, some methods may perform better.\n", "    \"\"\"\n", "    return (\"#NUMBER\" if token[0].isdigit() else token for token in tokens)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class NumberNormalizingVectorizer(TfidfVectorizer):\n", "    def build_tokenizer(self):\n", "        tokenize = super().build_tokenizer()\n", "        return lambda doc: list(number_normalizer(tokenize(doc)))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["exclude 'comp.os.ms-windows.misc'"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["categories = ['alt.atheism', 'comp.graphics',\n", "              'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware',\n", "              'comp.windows.x', 'misc.forsale', 'rec.autos',\n", "              'rec.motorcycles', 'rec.sport.baseball',\n", "              'rec.sport.hockey', 'sci.crypt', 'sci.electronics',\n", "              'sci.med', 'sci.space', 'soc.religion.christian',\n", "              'talk.politics.guns', 'talk.politics.mideast',\n", "              'talk.politics.misc', 'talk.religion.misc']\n", "newsgroups = fetch_20newsgroups(categories=categories)\n", "y_true = newsgroups.target"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["vectorizer = NumberNormalizingVectorizer(stop_words='english', min_df=5)\n", "cocluster = SpectralCoclustering(n_clusters=len(categories),\n", "                                 svd_method='arpack', random_state=0)\n", "kmeans = MiniBatchKMeans(n_clusters=len(categories), batch_size=20000,\n", "                         random_state=0)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"Vectorizing...\")\n", "X = vectorizer.fit_transform(newsgroups.data)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"Coclustering...\")\n", "start_time = time()\n", "cocluster.fit(X)\n", "y_cocluster = cocluster.row_labels_\n", "print(\"Done in {:.2f}s. V-measure: {:.4f}\".format(\n", "    time() - start_time,\n", "    v_measure_score(y_cocluster, y_true)))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"MiniBatchKMeans...\")\n", "start_time = time()\n", "y_kmeans = kmeans.fit_predict(X)\n", "print(\"Done in {:.2f}s. V-measure: {:.4f}\".format(\n", "    time() - start_time,\n", "    v_measure_score(y_kmeans, y_true)))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["feature_names = vectorizer.get_feature_names()\n", "document_names = list(newsgroups.target_names[i] for i in newsgroups.target)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def bicluster_ncut(i):\n", "    rows, cols = cocluster.get_indices(i)\n", "    if not (np.any(rows) and np.any(cols)):\n", "        import sys\n", "        return sys.float_info.max\n", "    row_complement = np.nonzero(np.logical_not(cocluster.rows_[i]))[0]\n", "    col_complement = np.nonzero(np.logical_not(cocluster.columns_[i]))[0]\n", "    # Note: the following is identical to X[rows[:, np.newaxis],\n", "    # cols].sum() but much faster in scipy <= 0.16\n", "    weight = X[rows][:, cols].sum()\n", "    cut = (X[row_complement][:, cols].sum() +\n", "           X[rows][:, col_complement].sum())\n", "    return cut / weight"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def most_common(d):\n", "    \"\"\"Items of a defaultdict(int) with the highest values.\n", "    Like Counter.most_common in Python >=2.7.\n", "    \"\"\"\n", "    return sorted(d.items(), key=operator.itemgetter(1), reverse=True)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["bicluster_ncuts = list(bicluster_ncut(i)\n", "                       for i in range(len(newsgroups.target_names)))\n", "best_idx = np.argsort(bicluster_ncuts)[:5]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print()\n", "print(\"Best biclusters:\")\n", "print(\"----------------\")\n", "for idx, cluster in enumerate(best_idx):\n", "    n_rows, n_cols = cocluster.get_shape(cluster)\n", "    cluster_docs, cluster_words = cocluster.get_indices(cluster)\n", "    if not len(cluster_docs) or not len(cluster_words):\n", "        continue\n\n", "    # categories\n", "    counter = defaultdict(int)\n", "    for i in cluster_docs:\n", "        counter[document_names[i]] += 1\n", "    cat_string = \", \".join(\"{:.0f}% {}\".format(float(c) / n_rows * 100, name)\n", "                           for name, c in most_common(counter)[:3])\n\n", "    # words\n", "    out_of_cluster_docs = cocluster.row_labels_ != cluster\n", "    out_of_cluster_docs = np.where(out_of_cluster_docs)[0]\n", "    word_col = X[:, cluster_words]\n", "    word_scores = np.array(word_col[cluster_docs, :].sum(axis=0) -\n", "                           word_col[out_of_cluster_docs, :].sum(axis=0))\n", "    word_scores = word_scores.ravel()\n", "    important_words = list(feature_names[cluster_words[i]]\n", "                           for i in word_scores.argsort()[:-11:-1])\n", "    print(\"bicluster {} : {} documents, {} words\".format(\n", "        idx, n_rows, n_cols))\n", "    print(\"categories   : {}\".format(cat_string))\n", "    print(\"words        : {}\\n\".format(', '.join(important_words)))"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}