{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "================================================================<br>\n", "Comparing different hierarchical linkage methods on toy datasets<br>\n", "================================================================<br>\n", "This example shows characteristics of different linkage<br>\n", "methods for hierarchical clustering on datasets that are<br>\n", "\"interesting\" but still in 2D.<br>\n", "The main observations to make are:<br>\n", "- single linkage is fast, and can perform well on<br>\n", "  non-globular data, but it performs poorly in the<br>\n", "  presence of noise.<br>\n", "- average and complete linkage perform well on<br>\n", "  cleanly separated globular clusters, but have mixed<br>\n", "  results otherwise.<br>\n", "- Ward is the most effective method for noisy data.<br>\n", "While these examples give some intuition about the<br>\n", "algorithms, this intuition might not apply to very high<br>\n", "dimensional data.<br>\n", ""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(__doc__)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import time\n", "import warnings"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "import matplotlib.pyplot as plt"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn import cluster, datasets\n", "from sklearn.preprocessing import StandardScaler\n", "from itertools import cycle, islice"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["np.random.seed(0)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["####################################################################<br>\n", "Generate datasets. We choose the size big enough to see the scalability<br>\n", "of the algorithms, but not too big to avoid too long running times"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["n_samples = 1500\n", "noisy_circles = datasets.make_circles(n_samples=n_samples, factor=.5,\n", "                                      noise=.05)\n", "noisy_moons = datasets.make_moons(n_samples=n_samples, noise=.05)\n", "blobs = datasets.make_blobs(n_samples=n_samples, random_state=8)\n", "no_structure = np.random.rand(n_samples, 2), None"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Anisotropicly distributed data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["random_state = 170\n", "X, y = datasets.make_blobs(n_samples=n_samples, random_state=random_state)\n", "transformation = [[0.6, -0.6], [-0.4, 0.8]]\n", "X_aniso = np.dot(X, transformation)\n", "aniso = (X_aniso, y)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["blobs with varied variances"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["varied = datasets.make_blobs(n_samples=n_samples,\n", "                             cluster_std=[1.0, 2.5, 0.5],\n", "                             random_state=random_state)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["####################################################################<br>\n", "Run the clustering and plot"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Set up cluster parameters"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(9 * 1.3 + 2, 14.5))\n", "plt.subplots_adjust(left=.02, right=.98, bottom=.001, top=.96, wspace=.05,\n", "                    hspace=.01)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plot_num = 1"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["default_base = {'n_neighbors': 10,\n", "                'n_clusters': 3}"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["datasets = [\n", "    (noisy_circles, {'n_clusters': 2}),\n", "    (noisy_moons, {'n_clusters': 2}),\n", "    (varied, {'n_neighbors': 2}),\n", "    (aniso, {'n_neighbors': 2}),\n", "    (blobs, {}),\n", "    (no_structure, {})]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for i_dataset, (dataset, algo_params) in enumerate(datasets):\n", "    # update parameters with dataset-specific values\n", "    params = default_base.copy()\n", "    params.update(algo_params)\n", "    X, y = dataset\n\n", "    # normalize dataset for easier parameter selection\n", "    X = StandardScaler().fit_transform(X)\n\n", "    # ============\n", "    # Create cluster objects\n", "    # ============\n", "    ward = cluster.AgglomerativeClustering(\n", "        n_clusters=params['n_clusters'], linkage='ward')\n", "    complete = cluster.AgglomerativeClustering(\n", "        n_clusters=params['n_clusters'], linkage='complete')\n", "    average = cluster.AgglomerativeClustering(\n", "        n_clusters=params['n_clusters'], linkage='average')\n", "    single = cluster.AgglomerativeClustering(\n", "        n_clusters=params['n_clusters'], linkage='single')\n", "    clustering_algorithms = (\n", "        ('Single Linkage', single),\n", "        ('Average Linkage', average),\n", "        ('Complete Linkage', complete),\n", "        ('Ward Linkage', ward),\n", "    )\n", "    for name, algorithm in clustering_algorithms:\n", "        t0 = time.time()\n\n", "        # catch warnings related to kneighbors_graph\n", "        with warnings.catch_warnings():\n", "            warnings.filterwarnings(\n", "                \"ignore\",\n", "                message=\"the number of connected components of the \" +\n", "                \"connectivity matrix is [0-9]{1,2}\" +\n", "                \" > 1. Completing it to avoid stopping the tree early.\",\n", "                category=UserWarning)\n", "            algorithm.fit(X)\n", "        t1 = time.time()\n", "        if hasattr(algorithm, 'labels_'):\n", "            y_pred = algorithm.labels_.astype(np.int)\n", "        else:\n", "            y_pred = algorithm.predict(X)\n", "        plt.subplot(len(datasets), len(clustering_algorithms), plot_num)\n", "        if i_dataset == 0:\n", "            plt.title(name, size=18)\n", "        colors = np.array(list(islice(cycle(['#377eb8', '#ff7f00', '#4daf4a',\n", "                                             '#f781bf', '#a65628', '#984ea3',\n", "                                             '#999999', '#e41a1c', '#dede00']),\n", "                                      int(max(y_pred) + 1))))\n", "        plt.scatter(X[:, 0], X[:, 1], s=10, color=colors[y_pred])\n", "        plt.xlim(-2.5, 2.5)\n", "        plt.ylim(-2.5, 2.5)\n", "        plt.xticks(())\n", "        plt.yticks(())\n", "        plt.text(.99, .01, ('%.2fs' % (t1 - t0)).lstrip('0'),\n", "                 transform=plt.gca().transAxes, size=15,\n", "                 horizontalalignment='right')\n", "        plot_num += 1"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.show()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}