{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "==========================================================<br>\n", "Adjustment for chance in clustering performance evaluation<br>\n", "==========================================================<br>\n", "The following plots demonstrate the impact of the number of clusters and<br>\n", "number of samples on various clustering performance evaluation metrics.<br>\n", "Non-adjusted measures such as the V-Measure show a dependency between<br>\n", "the number of clusters and the number of samples: the mean V-Measure<br>\n", "of random labeling increases significantly as the number of clusters is<br>\n", "closer to the total number of samples used to compute the measure.<br>\n", "Adjusted for chance measure such as ARI display some random variations<br>\n", "centered around a mean score of 0.0 for any number of samples and<br>\n", "clusters.<br>\n", "Only adjusted measures can hence safely be used as a consensus index<br>\n", "to evaluate the average stability of clustering algorithms for a given<br>\n", "value of k on various overlapping sub-samples of the dataset.<br>\n", ""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(__doc__)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Author: Olivier Grisel <olivier.grisel@ensta.org><br>\n", "License: BSD 3 clause"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "import matplotlib.pyplot as plt\n", "from time import time\n", "from sklearn import metrics"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def uniform_labelings_scores(score_func, n_samples, n_clusters_range,\n", "                             fixed_n_classes=None, n_runs=5, seed=42):\n", "    \"\"\"Compute score for 2 random uniform cluster labelings.\n", "    Both random labelings have the same number of clusters for each value\n", "    possible value in ``n_clusters_range``.\n", "    When fixed_n_classes is not None the first labeling is considered a ground\n", "    truth class assignment with fixed number of classes.\n", "    \"\"\"\n", "    random_labels = np.random.RandomState(seed).randint\n", "    scores = np.zeros((len(n_clusters_range), n_runs))\n", "    if fixed_n_classes is not None:\n", "        labels_a = random_labels(low=0, high=fixed_n_classes, size=n_samples)\n", "    for i, k in enumerate(n_clusters_range):\n", "        for j in range(n_runs):\n", "            if fixed_n_classes is None:\n", "                labels_a = random_labels(low=0, high=k, size=n_samples)\n", "            labels_b = random_labels(low=0, high=k, size=n_samples)\n", "            scores[i, j] = score_func(labels_a, labels_b)\n", "    return scores"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def ami_score(U, V):\n", "    return metrics.adjusted_mutual_info_score(U, V)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["score_funcs = [\n", "    metrics.adjusted_rand_score,\n", "    metrics.v_measure_score,\n", "    ami_score,\n", "    metrics.mutual_info_score,\n", "]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["2 independent random clusterings with equal cluster number"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["n_samples = 100\n", "n_clusters_range = np.linspace(2, n_samples, 10).astype(np.int)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.figure(1)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plots = []\n", "names = []\n", "for score_func in score_funcs:\n", "    print(\"Computing %s for %d values of n_clusters and n_samples=%d\"\n", "          % (score_func.__name__, len(n_clusters_range), n_samples))\n", "    t0 = time()\n", "    scores = uniform_labelings_scores(score_func, n_samples, n_clusters_range)\n", "    print(\"done in %0.3fs\" % (time() - t0))\n", "    plots.append(plt.errorbar(\n", "        n_clusters_range, np.median(scores, axis=1), scores.std(axis=1))[0])\n", "    names.append(score_func.__name__)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.title(\"Clustering measures for 2 random uniform labelings\\n\"\n", "          \"with equal number of clusters\")\n", "plt.xlabel('Number of clusters (Number of samples is fixed to %d)' % n_samples)\n", "plt.ylabel('Score value')\n", "plt.legend(plots, names)\n", "plt.ylim(bottom=-0.05, top=1.05)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Random labeling with varying n_clusters against ground class labels<br>\n", "with fixed number of clusters"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["n_samples = 1000\n", "n_clusters_range = np.linspace(2, 100, 10).astype(np.int)\n", "n_classes = 10"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.figure(2)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plots = []\n", "names = []\n", "for score_func in score_funcs:\n", "    print(\"Computing %s for %d values of n_clusters and n_samples=%d\"\n", "          % (score_func.__name__, len(n_clusters_range), n_samples))\n", "    t0 = time()\n", "    scores = uniform_labelings_scores(score_func, n_samples, n_clusters_range,\n", "                                      fixed_n_classes=n_classes)\n", "    print(\"done in %0.3fs\" % (time() - t0))\n", "    plots.append(plt.errorbar(\n", "        n_clusters_range, scores.mean(axis=1), scores.std(axis=1))[0])\n", "    names.append(score_func.__name__)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.title(\"Clustering measures for random uniform labeling\\n\"\n", "          \"against reference assignment with %d classes\" % n_classes)\n", "plt.xlabel('Number of clusters (Number of samples is fixed to %d)' % n_samples)\n", "plt.ylabel('Score value')\n", "plt.ylim(bottom=-0.05, top=1.05)\n", "plt.legend(plots, names)\n", "plt.show()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}