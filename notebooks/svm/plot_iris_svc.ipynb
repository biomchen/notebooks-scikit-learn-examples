{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "==================================================<br>\n", "Plot different SVM classifiers in the iris dataset<br>\n", "==================================================<br>\n", "Comparison of different linear SVM classifiers on a 2D projection of the iris<br>\n", "dataset. We only consider the first 2 features of this dataset:<br>\n", "- Sepal length<br>\n", "- Sepal width<br>\n", "This example shows how to plot the decision surface for four SVM classifiers<br>\n", "with different kernels.<br>\n", "The linear models ``LinearSVC()`` and ``SVC(kernel='linear')`` yield slightly<br>\n", "different decision boundaries. This can be a consequence of the following<br>\n", "differences:<br>\n", "- ``LinearSVC`` minimizes the squared hinge loss while ``SVC`` minimizes the<br>\n", "  regular hinge loss.<br>\n", "- ``LinearSVC`` uses the One-vs-All (also known as One-vs-Rest) multiclass<br>\n", "  reduction while ``SVC`` uses the One-vs-One multiclass reduction.<br>\n", "Both linear models have linear decision boundaries (intersecting hyperplanes)<br>\n", "while the non-linear kernel models (polynomial or Gaussian RBF) have more<br>\n", "flexible non-linear decision boundaries with shapes that depend on the kind of<br>\n", "kernel and its parameters.<br>\n", ".. NOTE:: while plotting the decision function of classifiers for toy 2D<br>\n", "   datasets can help get an intuitive understanding of their respective<br>\n", "   expressive power, be aware that those intuitions don't always generalize to<br>\n", "   more realistic high-dimensional problems.<br>\n", ""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(__doc__)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "import matplotlib.pyplot as plt\n", "from sklearn import svm, datasets"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def make_meshgrid(x, y, h=.02):\n", "    \"\"\"Create a mesh of points to plot in\n", "    Parameters\n", "    ----------\n", "    x: data to base x-axis meshgrid on\n", "    y: data to base y-axis meshgrid on\n", "    h: stepsize for meshgrid, optional\n", "    Returns\n", "    -------\n", "    xx, yy : ndarray\n", "    \"\"\"\n", "    x_min, x_max = x.min() - 1, x.max() + 1\n", "    y_min, y_max = y.min() - 1, y.max() + 1\n", "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n", "                         np.arange(y_min, y_max, h))\n", "    return xx, yy"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def plot_contours(ax, clf, xx, yy, **params):\n", "    \"\"\"Plot the decision boundaries for a classifier.\n", "    Parameters\n", "    ----------\n", "    ax: matplotlib axes object\n", "    clf: a classifier\n", "    xx: meshgrid ndarray\n", "    yy: meshgrid ndarray\n", "    params: dictionary of params to pass to contourf, optional\n", "    \"\"\"\n", "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n", "    Z = Z.reshape(xx.shape)\n", "    out = ax.contourf(xx, yy, Z, **params)\n", "    return out"]}, {"cell_type": "markdown", "metadata": {}, "source": ["import some data to play with"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["iris = datasets.load_iris()\n", "# Take the first two features. We could avoid this by using a two-dim dataset\n", "X = iris.data[:, :2]\n", "y = iris.target"]}, {"cell_type": "markdown", "metadata": {}, "source": ["we create an instance of SVM and fit out data. We do not scale our<br>\n", "data since we want to plot the support vectors"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["C = 1.0  # SVM regularization parameter\n", "models = (svm.SVC(kernel='linear', C=C),\n", "          svm.LinearSVC(C=C, max_iter=10000),\n", "          svm.SVC(kernel='rbf', gamma=0.7, C=C),\n", "          svm.SVC(kernel='poly', degree=3, gamma='auto', C=C))\n", "models = (clf.fit(X, y) for clf in models)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["title for the plots"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["titles = ('SVC with linear kernel',\n", "          'LinearSVC (linear kernel)',\n", "          'SVC with RBF kernel',\n", "          'SVC with polynomial (degree 3) kernel')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Set-up 2x2 grid for plotting."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fig, sub = plt.subplots(2, 2)\n", "plt.subplots_adjust(wspace=0.4, hspace=0.4)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X0, X1 = X[:, 0], X[:, 1]\n", "xx, yy = make_meshgrid(X0, X1)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for clf, title, ax in zip(models, titles, sub.flatten()):\n", "    plot_contours(ax, clf, xx, yy,\n", "                  cmap=plt.cm.coolwarm, alpha=0.8)\n", "    ax.scatter(X0, X1, c=y, cmap=plt.cm.coolwarm, s=20, edgecolors='k')\n", "    ax.set_xlim(xx.min(), xx.max())\n", "    ax.set_ylim(yy.min(), yy.max())\n", "    ax.set_xlabel('Sepal length')\n", "    ax.set_ylabel('Sepal width')\n", "    ax.set_xticks(())\n", "    ax.set_yticks(())\n", "    ax.set_title(title)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.show()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}