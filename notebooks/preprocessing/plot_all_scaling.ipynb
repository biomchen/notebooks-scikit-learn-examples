{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["#!/usr/bin/env python\n", "# -*- coding: utf-8 -*-"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "=============================================================<br>\n", "Compare the effect of different scalers on data with outliers<br>\n", "=============================================================<br>\n", "Feature 0 (median income in a block) and feature 5 (number of households) of<br>\n", "the `California housing dataset<br>\n", "<https://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html>`_ have very<br>\n", "different scales and contain some very large outliers. These two<br>\n", "characteristics lead to difficulties to visualize the data and, more<br>\n", "importantly, they can degrade the predictive performance of many machine<br>\n", "learning algorithms. Unscaled data can also slow down or even prevent the<br>\n", "convergence of many gradient-based estimators.<br>\n", "Indeed many estimators are designed with the assumption that each feature takes<br>\n", "values close to zero or more importantly that all features vary on comparable<br>\n", "scales. In particular, metric-based and gradient-based estimators often assume<br>\n", "approximately standardized data (centered features with unit variances). A<br>\n", "notable exception are decision tree-based estimators that are robust to<br>\n", "arbitrary scaling of the data.<br>\n", "This example uses different scalers, transformers, and normalizers to bring the<br>\n", "data within a pre-defined range.<br>\n", "Scalers are linear (or more precisely affine) transformers and differ from each<br>\n", "other in the way to estimate the parameters used to shift and scale each<br>\n", "feature.<br>\n", "``QuantileTransformer`` provides non-linear transformations in which distances<br>\n", "between marginal outliers and inliers are shrunk. ``PowerTransformer`` provides<br>\n", "non-linear transformations in which data is mapped to a normal distribution to<br>\n", "stabilize variance and minimize skewness.<br>\n", "Unlike the previous transformations, normalization refers to a per sample<br>\n", "transformation instead of a per feature transformation.<br>\n", "The following code is a bit verbose, feel free to jump directly to the analysis<br>\n", "of the results_.<br>\n", ""]}, {"cell_type": "markdown", "metadata": {}, "source": ["Author:  Raghav RV <rvraghav93@gmail.com><br>\n", "         Guillaume Lemaitre <g.lemaitre58@gmail.com><br>\n", "         Thomas Unterthiner<br>\n", "License: BSD 3 clause"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import matplotlib as mpl\n", "from matplotlib import pyplot as plt\n", "from matplotlib import cm"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.preprocessing import MinMaxScaler\n", "from sklearn.preprocessing import minmax_scale\n", "from sklearn.preprocessing import MaxAbsScaler\n", "from sklearn.preprocessing import StandardScaler\n", "from sklearn.preprocessing import RobustScaler\n", "from sklearn.preprocessing import Normalizer\n", "from sklearn.preprocessing import QuantileTransformer\n", "from sklearn.preprocessing import PowerTransformer"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.datasets import fetch_california_housing"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(__doc__)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["dataset = fetch_california_housing()\n", "X_full, y_full = dataset.data, dataset.target"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Take only 2 features to make visualization easier<br>\n", "Feature of 0 has a long tail distribution.<br>\n", "Feature 5 has a few but very large outliers."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X = X_full[:, [0, 5]]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["distributions = [\n", "    ('Unscaled data', X),\n", "    ('Data after standard scaling',\n", "        StandardScaler().fit_transform(X)),\n", "    ('Data after min-max scaling',\n", "        MinMaxScaler().fit_transform(X)),\n", "    ('Data after max-abs scaling',\n", "        MaxAbsScaler().fit_transform(X)),\n", "    ('Data after robust scaling',\n", "        RobustScaler(quantile_range=(25, 75)).fit_transform(X)),\n", "    ('Data after power transformation (Yeo-Johnson)',\n", "     PowerTransformer(method='yeo-johnson').fit_transform(X)),\n", "    ('Data after power transformation (Box-Cox)',\n", "     PowerTransformer(method='box-cox').fit_transform(X)),\n", "    ('Data after quantile transformation (gaussian pdf)',\n", "        QuantileTransformer(output_distribution='normal')\n", "        .fit_transform(X)),\n", "    ('Data after quantile transformation (uniform pdf)',\n", "        QuantileTransformer(output_distribution='uniform')\n", "        .fit_transform(X)),\n", "    ('Data after sample-wise L2 normalizing',\n", "        Normalizer().fit_transform(X)),\n", "]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["scale the output between 0 and 1 for the colorbar"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["y = minmax_scale(y_full)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["plasma does not exist in matplotlib < 1.5"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["cmap = getattr(cm, 'plasma_r', cm.hot_r)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def create_axes(title, figsize=(16, 6)):\n", "    fig = plt.figure(figsize=figsize)\n", "    fig.suptitle(title)\n\n", "    # define the axis for the first plot\n", "    left, width = 0.1, 0.22\n", "    bottom, height = 0.1, 0.7\n", "    bottom_h = height + 0.15\n", "    left_h = left + width + 0.02\n", "    rect_scatter = [left, bottom, width, height]\n", "    rect_histx = [left, bottom_h, width, 0.1]\n", "    rect_histy = [left_h, bottom, 0.05, height]\n", "    ax_scatter = plt.axes(rect_scatter)\n", "    ax_histx = plt.axes(rect_histx)\n", "    ax_histy = plt.axes(rect_histy)\n\n", "    # define the axis for the zoomed-in plot\n", "    left = width + left + 0.2\n", "    left_h = left + width + 0.02\n", "    rect_scatter = [left, bottom, width, height]\n", "    rect_histx = [left, bottom_h, width, 0.1]\n", "    rect_histy = [left_h, bottom, 0.05, height]\n", "    ax_scatter_zoom = plt.axes(rect_scatter)\n", "    ax_histx_zoom = plt.axes(rect_histx)\n", "    ax_histy_zoom = plt.axes(rect_histy)\n\n", "    # define the axis for the colorbar\n", "    left, width = width + left + 0.13, 0.01\n", "    rect_colorbar = [left, bottom, width, height]\n", "    ax_colorbar = plt.axes(rect_colorbar)\n", "    return ((ax_scatter, ax_histy, ax_histx),\n", "            (ax_scatter_zoom, ax_histy_zoom, ax_histx_zoom),\n", "            ax_colorbar)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def plot_distribution(axes, X, y, hist_nbins=50, title=\"\",\n", "                      x0_label=\"\", x1_label=\"\"):\n", "    ax, hist_X1, hist_X0 = axes\n", "    ax.set_title(title)\n", "    ax.set_xlabel(x0_label)\n", "    ax.set_ylabel(x1_label)\n\n", "    # The scatter plot\n", "    colors = cmap(y)\n", "    ax.scatter(X[:, 0], X[:, 1], alpha=0.5, marker='o', s=5, lw=0, c=colors)\n\n", "    # Removing the top and the right spine for aesthetics\n", "    # make nice axis layout\n", "    ax.spines['top'].set_visible(False)\n", "    ax.spines['right'].set_visible(False)\n", "    ax.get_xaxis().tick_bottom()\n", "    ax.get_yaxis().tick_left()\n", "    ax.spines['left'].set_position(('outward', 10))\n", "    ax.spines['bottom'].set_position(('outward', 10))\n\n", "    # Histogram for axis X1 (feature 5)\n", "    hist_X1.set_ylim(ax.get_ylim())\n", "    hist_X1.hist(X[:, 1], bins=hist_nbins, orientation='horizontal',\n", "                 color='grey', ec='grey')\n", "    hist_X1.axis('off')\n\n", "    # Histogram for axis X0 (feature 0)\n", "    hist_X0.set_xlim(ax.get_xlim())\n", "    hist_X0.hist(X[:, 0], bins=hist_nbins, orientation='vertical',\n", "                 color='grey', ec='grey')\n", "    hist_X0.axis('off')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#############################################################################<br>\n", "Two plots will be shown for each scaler/normalizer/transformer. The left<br>\n", "figure will show a scatter plot of the full data set while the right figure<br>\n", "will exclude the extreme values considering only 99 % of the data set,<br>\n", "excluding marginal outliers. In addition, the marginal distributions for each<br>\n", "feature will be shown on the side of the scatter plot."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def make_plot(item_idx):\n", "    title, X = distributions[item_idx]\n", "    ax_zoom_out, ax_zoom_in, ax_colorbar = create_axes(title)\n", "    axarr = (ax_zoom_out, ax_zoom_in)\n", "    plot_distribution(axarr[0], X, y, hist_nbins=200,\n", "                      x0_label=\"Median Income\",\n", "                      x1_label=\"Number of households\",\n", "                      title=\"Full data\")\n\n", "    # zoom-in\n", "    zoom_in_percentile_range = (0, 99)\n", "    cutoffs_X0 = np.percentile(X[:, 0], zoom_in_percentile_range)\n", "    cutoffs_X1 = np.percentile(X[:, 1], zoom_in_percentile_range)\n", "    non_outliers_mask = (\n", "        np.all(X > [cutoffs_X0[0], cutoffs_X1[0]], axis=1) &\n", "        np.all(X < [cutoffs_X0[1], cutoffs_X1[1]], axis=1))\n", "    plot_distribution(axarr[1], X[non_outliers_mask], y[non_outliers_mask],\n", "                      hist_nbins=50,\n", "                      x0_label=\"Median Income\",\n", "                      x1_label=\"Number of households\",\n", "                      title=\"Zoom-in\")\n", "    norm = mpl.colors.Normalize(y_full.min(), y_full.max())\n", "    mpl.colorbar.ColorbarBase(ax_colorbar, cmap=cmap,\n", "                              norm=norm, orientation='vertical',\n", "                              label='Color mapping for values of y')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["######################################################################<br>\n", ".. _results:<br>\n", "<br>\n", "Original data<br>\n", "-------------<br>\n", "<br>\n", "Each transformation is plotted showing two transformed features, with the<br>\n", "left plot showing the entire dataset, and the right zoomed-in to show the<br>\n", "dataset without the marginal outliers. A large majority of the samples are<br>\n", "compacted to a specific range, [0, 10] for the median income and [0, 6] for<br>\n", "the number of households. Note that there are some marginal outliers (some<br>\n", "blocks have more than 1200 households). Therefore, a specific pre-processing<br>\n", "can be very beneficial depending of the application. In the following, we<br>\n", "present some insights and behaviors of those pre-processing methods in the<br>\n", "presence of marginal outliers."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["make_plot(0)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#####################################################################<br>\n", "StandardScaler<br>\n", "--------------<br>\n", "<br>\n", "``StandardScaler`` removes the mean and scales the data to unit variance.<br>\n", "However, the outliers have an influence when computing the empirical mean and<br>\n", "standard deviation which shrink the range of the feature values as shown in<br>\n", "the left figure below. Note in particular that because the outliers on each<br>\n", "feature have different magnitudes, the spread of the transformed data on<br>\n", "each feature is very different: most of the data lie in the [-2, 4] range for<br>\n", "the transformed median income feature while the same data is squeezed in the<br>\n", "smaller [-0.2, 0.2] range for the transformed number of households.<br>\n", "<br>\n", "``StandardScaler`` therefore cannot guarantee balanced feature scales in the<br>\n", "presence of outliers."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["make_plot(1)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["########################################################################<br>\n", "MinMaxScaler<br>\n", "------------<br>\n", "<br>\n", "``MinMaxScaler`` rescales the data set such that all feature values are in<br>\n", "the range [0, 1] as shown in the right panel below. However, this scaling<br>\n", "compress all inliers in the narrow range [0, 0.005] for the transformed<br>\n", "number of households.<br>\n", "<br>\n", "As ``StandardScaler``, ``MinMaxScaler`` is very sensitive to the presence of<br>\n", "outliers."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["make_plot(2)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["###########################################################################<br>\n", "MaxAbsScaler<br>\n", "------------<br>\n", "<br>\n", "``MaxAbsScaler`` differs from the previous scaler such that the absolute<br>\n", "values are mapped in the range [0, 1]. On positive only data, this scaler<br>\n", "behaves similarly to ``MinMaxScaler`` and therefore also suffers from the<br>\n", "presence of large outliers."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["make_plot(3)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["############################################################################<br>\n", "RobustScaler<br>\n", "------------<br>\n", "<br>\n", "Unlike the previous scalers, the centering and scaling statistics of this<br>\n", "scaler are based on percentiles and are therefore not influenced by a few<br>\n", "number of very large marginal outliers. Consequently, the resulting range of<br>\n", "the transformed feature values is larger than for the previous scalers and,<br>\n", "more importantly, are approximately similar: for both features most of the<br>\n", "transformed values lie in a [-2, 3] range as seen in the zoomed-in figure.<br>\n", "Note that the outliers themselves are still present in the transformed data.<br>\n", "If a separate outlier clipping is desirable, a non-linear transformation is<br>\n", "required (see below)."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["make_plot(4)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["############################################################################<br>\n", "PowerTransformer<br>\n", "----------------<br>\n", "<br>\n", "``PowerTransformer`` applies a power transformation to each feature to make<br>\n", "the data more Gaussian-like. Currently, ``PowerTransformer`` implements the<br>\n", "Yeo-Johnson and Box-Cox transforms. The power transform finds the optimal<br>\n", "scaling factor to stabilize variance and mimimize skewness through maximum<br>\n", "likelihood estimation. By default, ``PowerTransformer`` also applies<br>\n", "zero-mean, unit variance normalization to the transformed output. Note that<br>\n", "Box-Cox can only be applied to strictly positive data. Income and number of<br>\n", "households happen to be strictly positive, but if negative values are present<br>\n", "the Yeo-Johnson transformed is to be preferred."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["make_plot(5)\n", "make_plot(6)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["############################################################################<br>\n", "QuantileTransformer (Gaussian output)<br>\n", "-------------------------------------<br>\n", "<br>\n", "``QuantileTransformer`` has an additional ``output_distribution`` parameter<br>\n", "allowing to match a Gaussian distribution instead of a uniform distribution.<br>\n", "Note that this non-parametetric transformer introduces saturation artifacts<br>\n", "for extreme values."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["make_plot(7)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#################################################################<br>\n", "QuantileTransformer (uniform output)<br>\n", "------------------------------------<br>\n", "<br>\n", "``QuantileTransformer`` applies a non-linear transformation such that the<br>\n", "probability density function of each feature will be mapped to a uniform<br>\n", "distribution. In this case, all the data will be mapped in the range [0, 1],<br>\n", "even the outliers which cannot be distinguished anymore from the inliers.<br>\n", "<br>\n", "As ``RobustScaler``, ``QuantileTransformer`` is robust to outliers in the<br>\n", "sense that adding or removing outliers in the training set will yield<br>\n", "approximately the same transformation on held out data. But contrary to<br>\n", "``RobustScaler``, ``QuantileTransformer`` will also automatically collapse<br>\n", "any outlier by setting them to the a priori defined range boundaries (0 and<br>\n", "1)."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["make_plot(8)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["############################################################################<br>\n", "Normalizer<br>\n", "----------<br>\n", "<br>\n", "The ``Normalizer`` rescales the vector for each sample to have unit norm,<br>\n", "independently of the distribution of the samples. It can be seen on both<br>\n", "figures below where all samples are mapped onto the unit circle. In our<br>\n", "example the two selected features have only positive values; therefore the<br>\n", "transformed data only lie in the positive quadrant. This would not be the<br>\n", "case if some original features had a mix of positive and negative values."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["make_plot(9)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.show()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}