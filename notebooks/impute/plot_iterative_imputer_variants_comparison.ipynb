{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "=========================================================<br>\n", "Imputing missing values with variants of IterativeImputer<br>\n", "=========================================================<br>\n", "The :class:`sklearn.impute.IterativeImputer` class is very flexible - it can be<br>\n", "used with a variety of estimators to do round-robin regression, treating every<br>\n", "variable as an output in turn.<br>\n", "In this example we compare some estimators for the purpose of missing feature<br>\n", "imputation with :class:`sklearn.impute.IterativeImputer`:<br>\n", "* :class:`~sklearn.linear_model.BayesianRidge`: regularized linear regression<br>\n", "* :class:`~sklearn.tree.DecisionTreeRegressor`: non-linear regression<br>\n", "* :class:`~sklearn.ensemble.ExtraTreesRegressor`: similar to missForest in R<br>\n", "* :class:`~sklearn.neighbors.KNeighborsRegressor`: comparable to other KNN<br>\n", "  imputation approaches<br>\n", "Of particular interest is the ability of<br>\n", ":class:`sklearn.impute.IterativeImputer` to mimic the behavior of missForest, a<br>\n", "popular imputation package for R. In this example, we have chosen to use<br>\n", ":class:`sklearn.ensemble.ExtraTreesRegressor` instead of<br>\n", ":class:`sklearn.ensemble.RandomForestRegressor` (as in missForest) due to its<br>\n", "increased speed.<br>\n", "Note that :class:`sklearn.neighbors.KNeighborsRegressor` is different from KNN<br>\n", "imputation, which learns from samples with missing values by using a distance<br>\n", "metric that accounts for missing values, rather than imputing them.<br>\n", "The goal is to compare different estimators to see which one is best for the<br>\n", ":class:`sklearn.impute.IterativeImputer` when using a<br>\n", ":class:`sklearn.linear_model.BayesianRidge` estimator on the California housing<br>\n", "dataset with a single value randomly removed from each row.<br>\n", "For this particular pattern of missing values we see that<br>\n", ":class:`sklearn.ensemble.ExtraTreesRegressor` and<br>\n", ":class:`sklearn.linear_model.BayesianRidge` give the best results.<br>\n", ""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(__doc__)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "import matplotlib.pyplot as plt\n", "import pandas as pd"]}, {"cell_type": "markdown", "metadata": {}, "source": ["To use this experimental feature, we need to explicitly ask for it:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.experimental import enable_iterative_imputer  # noqa\n", "from sklearn.datasets import fetch_california_housing\n", "from sklearn.impute import SimpleImputer\n", "from sklearn.impute import IterativeImputer\n", "from sklearn.linear_model import BayesianRidge\n", "from sklearn.tree import DecisionTreeRegressor\n", "from sklearn.ensemble import ExtraTreesRegressor\n", "from sklearn.neighbors import KNeighborsRegressor\n", "from sklearn.pipeline import make_pipeline\n", "from sklearn.model_selection import cross_val_score"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["N_SPLITS = 5"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["rng = np.random.RandomState(0)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X_full, y_full = fetch_california_housing(return_X_y=True)\n", "# ~2k samples is enough for the purpose of the example.\n", "# Remove the following two lines for a slower run with different error bars.\n", "X_full = X_full[::10]\n", "y_full = y_full[::10]\n", "n_samples, n_features = X_full.shape"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Estimate the score on the entire dataset, with no missing values"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["br_estimator = BayesianRidge()\n", "score_full_data = pd.DataFrame(\n", "    cross_val_score(\n", "        br_estimator, X_full, y_full, scoring='neg_mean_squared_error',\n", "        cv=N_SPLITS\n", "    ),\n", "    columns=['Full Data']\n", ")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Add a single missing value to each row"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X_missing = X_full.copy()\n", "y_missing = y_full\n", "missing_samples = np.arange(n_samples)\n", "missing_features = rng.choice(n_features, n_samples, replace=True)\n", "X_missing[missing_samples, missing_features] = np.nan"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Estimate the score after imputation (mean and median strategies)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["score_simple_imputer = pd.DataFrame()\n", "for strategy in ('mean', 'median'):\n", "    estimator = make_pipeline(\n", "        SimpleImputer(missing_values=np.nan, strategy=strategy),\n", "        br_estimator\n", "    )\n", "    score_simple_imputer[strategy] = cross_val_score(\n", "        estimator, X_missing, y_missing, scoring='neg_mean_squared_error',\n", "        cv=N_SPLITS\n", "    )"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Estimate the score after iterative imputation of the missing values<br>\n", "with different estimators"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["estimators = [\n", "    BayesianRidge(),\n", "    DecisionTreeRegressor(max_features='sqrt', random_state=0),\n", "    ExtraTreesRegressor(n_estimators=10, random_state=0),\n", "    KNeighborsRegressor(n_neighbors=15)\n", "]\n", "score_iterative_imputer = pd.DataFrame()\n", "for impute_estimator in estimators:\n", "    estimator = make_pipeline(\n", "        IterativeImputer(random_state=0, estimator=impute_estimator),\n", "        br_estimator\n", "    )\n", "    score_iterative_imputer[impute_estimator.__class__.__name__] = \\\n", "        cross_val_score(\n", "            estimator, X_missing, y_missing, scoring='neg_mean_squared_error',\n", "            cv=N_SPLITS\n", "        )"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["scores = pd.concat(\n", "    [score_full_data, score_simple_imputer, score_iterative_imputer],\n", "    keys=['Original', 'SimpleImputer', 'IterativeImputer'], axis=1\n", ")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["plot boston results"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fig, ax = plt.subplots(figsize=(13, 6))\n", "means = -scores.mean()\n", "errors = scores.std()\n", "means.plot.barh(xerr=errors, ax=ax)\n", "ax.set_title('California Housing Regression with Different Imputation Methods')\n", "ax.set_xlabel('MSE (smaller is better)')\n", "ax.set_yticks(np.arange(means.shape[0]))\n", "ax.set_yticklabels([\" w/ \".join(label) for label in means.index.tolist()])\n", "plt.tight_layout(pad=1)\n", "plt.show()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}