{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "=================================<br>\n", "Gaussian Mixture Model Ellipsoids<br>\n", "=================================<br>\n", "Plot the confidence ellipsoids of a mixture of two Gaussians<br>\n", "obtained with Expectation Maximisation (``GaussianMixture`` class) and<br>\n", "Variational Inference (``BayesianGaussianMixture`` class models with<br>\n", "a Dirichlet process prior).<br>\n", "Both models have access to five components with which to fit the data. Note<br>\n", "that the Expectation Maximisation model will necessarily use all five<br>\n", "components while the Variational Inference model will effectively only use as<br>\n", "many as are needed for a good fit. Here we can see that the Expectation<br>\n", "Maximisation model splits some components arbitrarily, because it is trying to<br>\n", "fit too many components, while the Dirichlet Process model adapts it number of<br>\n", "state automatically.<br>\n", "This example doesn't show it, as we're in a low-dimensional space, but<br>\n", "another advantage of the Dirichlet process model is that it can fit<br>\n", "full covariance matrices effectively even when there are less examples<br>\n", "per cluster than there are dimensions in the data, due to<br>\n", "regularization properties of the inference algorithm.<br>\n", ""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import itertools"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "from scipy import linalg\n", "import matplotlib.pyplot as plt\n", "import matplotlib as mpl"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn import mixture"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["color_iter = itertools.cycle(['navy', 'c', 'cornflowerblue', 'gold',\n", "                              'darkorange'])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def plot_results(X, Y_, means, covariances, index, title):\n", "    splot = plt.subplot(2, 1, 1 + index)\n", "    for i, (mean, covar, color) in enumerate(zip(\n", "            means, covariances, color_iter)):\n", "        v, w = linalg.eigh(covar)\n", "        v = 2. * np.sqrt(2.) * np.sqrt(v)\n", "        u = w[0] / linalg.norm(w[0])\n", "        # as the DP will not use every component it has access to\n", "        # unless it needs it, we shouldn't plot the redundant\n", "        # components.\n", "        if not np.any(Y_ == i):\n", "            continue\n", "        plt.scatter(X[Y_ == i, 0], X[Y_ == i, 1], .8, color=color)\n\n", "        # Plot an ellipse to show the Gaussian component\n", "        angle = np.arctan(u[1] / u[0])\n", "        angle = 180. * angle / np.pi  # convert to degrees\n", "        ell = mpl.patches.Ellipse(mean, v[0], v[1], 180. + angle, color=color)\n", "        ell.set_clip_box(splot.bbox)\n", "        ell.set_alpha(0.5)\n", "        splot.add_artist(ell)\n", "    plt.xlim(-9., 5.)\n", "    plt.ylim(-3., 6.)\n", "    plt.xticks(())\n", "    plt.yticks(())\n", "    plt.title(title)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Number of samples per component"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["n_samples = 500"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Generate random sample, two components"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["np.random.seed(0)\n", "C = np.array([[0., -0.1], [1.7, .4]])\n", "X = np.r_[np.dot(np.random.randn(n_samples, 2), C),\n", "          .7 * np.random.randn(n_samples, 2) + np.array([-6, 3])]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Fit a Gaussian mixture with EM using five components"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["gmm = mixture.GaussianMixture(n_components=5, covariance_type='full').fit(X)\n", "plot_results(X, gmm.predict(X), gmm.means_, gmm.covariances_, 0,\n", "             'Gaussian Mixture')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Fit a Dirichlet process Gaussian mixture using five components"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["dpgmm = mixture.BayesianGaussianMixture(n_components=5,\n", "                                        covariance_type='full').fit(X)\n", "plot_results(X, dpgmm.predict(X), dpgmm.means_, dpgmm.covariances_, 1,\n", "             'Bayesian Gaussian Mixture with a Dirichlet process prior')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.show()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}