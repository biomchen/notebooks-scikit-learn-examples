{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "================================<br>\n", "Gaussian Mixture Model Selection<br>\n", "================================<br>\n", "This example shows that model selection can be performed with<br>\n", "Gaussian Mixture Models using information-theoretic criteria (BIC).<br>\n", "Model selection concerns both the covariance type<br>\n", "and the number of components in the model.<br>\n", "In that case, AIC also provides the right result (not shown to save time),<br>\n", "but BIC is better suited if the problem is to identify the right model.<br>\n", "Unlike Bayesian procedures, such inferences are prior-free.<br>\n", "In that case, the model with 2 components and full covariance<br>\n", "(which corresponds to the true generative model) is selected.<br>\n", ""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "import itertools"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from scipy import linalg\n", "import matplotlib.pyplot as plt\n", "import matplotlib as mpl"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn import mixture"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(__doc__)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Number of samples per component"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["n_samples = 500"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Generate random sample, two components"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["np.random.seed(0)\n", "C = np.array([[0., -0.1], [1.7, .4]])\n", "X = np.r_[np.dot(np.random.randn(n_samples, 2), C),\n", "          .7 * np.random.randn(n_samples, 2) + np.array([-6, 3])]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["lowest_bic = np.infty\n", "bic = []\n", "n_components_range = range(1, 7)\n", "cv_types = ['spherical', 'tied', 'diag', 'full']\n", "for cv_type in cv_types:\n", "    for n_components in n_components_range:\n", "        # Fit a Gaussian mixture with EM\n", "        gmm = mixture.GaussianMixture(n_components=n_components,\n", "                                      covariance_type=cv_type)\n", "        gmm.fit(X)\n", "        bic.append(gmm.bic(X))\n", "        if bic[-1] < lowest_bic:\n", "            lowest_bic = bic[-1]\n", "            best_gmm = gmm"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["bic = np.array(bic)\n", "color_iter = itertools.cycle(['navy', 'turquoise', 'cornflowerblue',\n", "                              'darkorange'])\n", "clf = best_gmm\n", "bars = []"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Plot the BIC scores"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(8, 6))\n", "spl = plt.subplot(2, 1, 1)\n", "for i, (cv_type, color) in enumerate(zip(cv_types, color_iter)):\n", "    xpos = np.array(n_components_range) + .2 * (i - 2)\n", "    bars.append(plt.bar(xpos, bic[i * len(n_components_range):\n", "                                  (i + 1) * len(n_components_range)],\n", "                        width=.2, color=color))\n", "plt.xticks(n_components_range)\n", "plt.ylim([bic.min() * 1.01 - .01 * bic.max(), bic.max()])\n", "plt.title('BIC score per model')\n", "xpos = np.mod(bic.argmin(), len(n_components_range)) + .65 +\\\n", "    .2 * np.floor(bic.argmin() / len(n_components_range))\n", "plt.text(xpos, bic.min() * 0.97 + .03 * bic.max(), '*', fontsize=14)\n", "spl.set_xlabel('Number of components')\n", "spl.legend([b[0] for b in bars], cv_types)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Plot the winner"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["splot = plt.subplot(2, 1, 2)\n", "Y_ = clf.predict(X)\n", "for i, (mean, cov, color) in enumerate(zip(clf.means_, clf.covariances_,\n", "                                           color_iter)):\n", "    v, w = linalg.eigh(cov)\n", "    if not np.any(Y_ == i):\n", "        continue\n", "    plt.scatter(X[Y_ == i, 0], X[Y_ == i, 1], .8, color=color)\n\n", "    # Plot an ellipse to show the Gaussian component\n", "    angle = np.arctan2(w[0][1], w[0][0])\n", "    angle = 180. * angle / np.pi  # convert to degrees\n", "    v = 2. * np.sqrt(2.) * np.sqrt(v)\n", "    ell = mpl.patches.Ellipse(mean, v[0], v[1], 180. + angle, color=color)\n", "    ell.set_clip_box(splot.bbox)\n", "    ell.set_alpha(.5)\n", "    splot.add_artist(ell)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.xticks(())\n", "plt.yticks(())\n", "plt.title('Selected GMM: full model, 2 components')\n", "plt.subplots_adjust(hspace=.35, bottom=.02)\n", "plt.show()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}