{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "=====================================<br>\n", "Visualization of MLP weights on MNIST<br>\n", "=====================================<br>\n", "Sometimes looking at the learned coefficients of a neural network can provide<br>\n", "insight into the learning behavior. For example if weights look unstructured,<br>\n", "maybe some were not used at all, or if very large coefficients exist, maybe<br>\n", "regularization was too low or the learning rate too high.<br>\n", "This example shows how to plot some of the first layer weights in a<br>\n", "MLPClassifier trained on the MNIST dataset.<br>\n", "The input data consists of 28x28 pixel handwritten digits, leading to 784<br>\n", "features in the dataset. Therefore the first layer weight matrix have the shape<br>\n", "(784, hidden_layer_sizes[0]).  We can therefore visualize a single column of<br>\n", "the weight matrix as a 28x28 pixel image.<br>\n", "To make the example run faster, we use very few hidden units, and train only<br>\n", "for a very short time. Training longer would result in weights with a much<br>\n", "smoother spatial appearance.<br>\n", ""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import matplotlib.pyplot as plt\n", "from sklearn.datasets import fetch_openml\n", "from sklearn.neural_network import MLPClassifier"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(__doc__)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Load data from https://www.openml.org/d/554"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X, y = fetch_openml('mnist_784', version=1, return_X_y=True)\n", "X = X / 255."]}, {"cell_type": "markdown", "metadata": {}, "source": ["rescale the data, use the traditional train/test split"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X_train, X_test = X[:60000], X[60000:]\n", "y_train, y_test = y[:60000], y[60000:]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["mlp = MLPClassifier(hidden_layer_sizes=(50,), max_iter=10, alpha=1e-4,\n", "                    solver='sgd', verbose=10, random_state=1,\n", "                    learning_rate_init=.1)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["mlp.fit(X_train, y_train)\n", "print(\"Training set score: %f\" % mlp.score(X_train, y_train))\n", "print(\"Test set score: %f\" % mlp.score(X_test, y_test))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fig, axes = plt.subplots(4, 4)\n", "# use global min / max to ensure all weights are shown on the same scale\n", "vmin, vmax = mlp.coefs_[0].min(), mlp.coefs_[0].max()\n", "for coef, ax in zip(mlp.coefs_[0].T, axes.ravel()):\n", "    ax.matshow(coef.reshape(28, 28), cmap=plt.cm.gray, vmin=.5 * vmin,\n", "               vmax=.5 * vmax)\n", "    ax.set_xticks(())\n", "    ax.set_yticks(())"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.show()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}