{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "=======================================<br>\n", "Visualizing the stock market structure<br>\n", "=======================================<br>\n", "This example employs several unsupervised learning techniques to extract<br>\n", "the stock market structure from variations in historical quotes.<br>\n", "The quantity that we use is the daily variation in quote price: quotes<br>\n", "that are linked tend to cofluctuate during a day.<br>\n", ".. _stock_market:<br>\n", "Learning a graph structure<br>\n", "--------------------------<br>\n", "We use sparse inverse covariance estimation to find which quotes are<br>\n", "correlated conditionally on the others. Specifically, sparse inverse<br>\n", "covariance gives us a graph, that is a list of connection. For each<br>\n", "symbol, the symbols that it is connected too are those useful to explain<br>\n", "its fluctuations.<br>\n", "Clustering<br>\n", "----------<br>\n", "We use clustering to group together quotes that behave similarly. Here,<br>\n", "amongst the :ref:`various clustering techniques <clustering>` available<br>\n", "in the scikit-learn, we use :ref:`affinity_propagation` as it does<br>\n", "not enforce equal-size clusters, and it can choose automatically the<br>\n", "number of clusters from the data.<br>\n", "Note that this gives us a different indication than the graph, as the<br>\n", "graph reflects conditional relations between variables, while the<br>\n", "clustering reflects marginal properties: variables clustered together can<br>\n", "be considered as having a similar impact at the level of the full stock<br>\n", "market.<br>\n", "Embedding in 2D space<br>\n", "---------------------<br>\n", "For visualization purposes, we need to lay out the different symbols on a<br>\n", "2D canvas. For this we use :ref:`manifold` techniques to retrieve 2D<br>\n", "embedding.<br>\n", "Visualization<br>\n", "-------------<br>\n", "The output of the 3 models are combined in a 2D graph where nodes<br>\n", "represents the stocks and edges the:<br>\n", "- cluster labels are used to define the color of the nodes<br>\n", "- the sparse covariance model is used to display the strength of the edges<br>\n", "- the 2D embedding is used to position the nodes in the plan<br>\n", "This example has a fair amount of visualization-related code, as<br>\n", "visualization is crucial here to display the graph. One of the challenge<br>\n", "is to position the labels minimizing overlap. For this we use an<br>\n", "heuristic based on the direction of the nearest neighbor along each<br>\n", "axis.<br>\n", ""]}, {"cell_type": "markdown", "metadata": {}, "source": ["Author: Gael Varoquaux gael.varoquaux@normalesup.org<br>\n", "License: BSD 3 clause"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import sys"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "import matplotlib.pyplot as plt\n", "from matplotlib.collections import LineCollection"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import pandas as pd"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn import cluster, covariance, manifold"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(__doc__)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#############################################################################<br>\n", "Retrieve the data from Internet"]}, {"cell_type": "markdown", "metadata": {}, "source": ["The data is from 2003 - 2008. This is reasonably calm: (not too long ago so<br>\n", "that we get high-tech firms, and before the 2008 crash). This kind of<br>\n", "historical data can be obtained for from APIs like the quandl.com and<br>\n", "alphavantage.co ones."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["symbol_dict = {\n", "    'TOT': 'Total',\n", "    'XOM': 'Exxon',\n", "    'CVX': 'Chevron',\n", "    'COP': 'ConocoPhillips',\n", "    'VLO': 'Valero Energy',\n", "    'MSFT': 'Microsoft',\n", "    'IBM': 'IBM',\n", "    'TWX': 'Time Warner',\n", "    'CMCSA': 'Comcast',\n", "    'CVC': 'Cablevision',\n", "    'YHOO': 'Yahoo',\n", "    'DELL': 'Dell',\n", "    'HPQ': 'HP',\n", "    'AMZN': 'Amazon',\n", "    'TM': 'Toyota',\n", "    'CAJ': 'Canon',\n", "    'SNE': 'Sony',\n", "    'F': 'Ford',\n", "    'HMC': 'Honda',\n", "    'NAV': 'Navistar',\n", "    'NOC': 'Northrop Grumman',\n", "    'BA': 'Boeing',\n", "    'KO': 'Coca Cola',\n", "    'MMM': '3M',\n", "    'MCD': 'McDonald\\'s',\n", "    'PEP': 'Pepsi',\n", "    'K': 'Kellogg',\n", "    'UN': 'Unilever',\n", "    'MAR': 'Marriott',\n", "    'PG': 'Procter Gamble',\n", "    'CL': 'Colgate-Palmolive',\n", "    'GE': 'General Electrics',\n", "    'WFC': 'Wells Fargo',\n", "    'JPM': 'JPMorgan Chase',\n", "    'AIG': 'AIG',\n", "    'AXP': 'American express',\n", "    'BAC': 'Bank of America',\n", "    'GS': 'Goldman Sachs',\n", "    'AAPL': 'Apple',\n", "    'SAP': 'SAP',\n", "    'CSCO': 'Cisco',\n", "    'TXN': 'Texas Instruments',\n", "    'XRX': 'Xerox',\n", "    'WMT': 'Wal-Mart',\n", "    'HD': 'Home Depot',\n", "    'GSK': 'GlaxoSmithKline',\n", "    'PFE': 'Pfizer',\n", "    'SNY': 'Sanofi-Aventis',\n", "    'NVS': 'Novartis',\n", "    'KMB': 'Kimberly-Clark',\n", "    'R': 'Ryder',\n", "    'GD': 'General Dynamics',\n", "    'RTN': 'Raytheon',\n", "    'CVS': 'CVS',\n", "    'CAT': 'Caterpillar',\n", "    'DD': 'DuPont de Nemours'}"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["symbols, names = np.array(sorted(symbol_dict.items())).T"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["quotes = []"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for symbol in symbols:\n", "    print('Fetching quote history for %r' % symbol, file=sys.stderr)\n", "    url = ('https://raw.githubusercontent.com/scikit-learn/examples-data/'\n", "           'master/financial-data/{}.csv')\n", "    quotes.append(pd.read_csv(url.format(symbol)))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["close_prices = np.vstack([q['close'] for q in quotes])\n", "open_prices = np.vstack([q['open'] for q in quotes])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["The daily variations of the quotes are what carry most information"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["variation = close_prices - open_prices"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#############################################################################<br>\n", "Learn a graphical structure from the correlations"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["edge_model = covariance.GraphicalLassoCV()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["standardize the time series: using correlations rather than covariance<br>\n", "is more efficient for structure recovery"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X = variation.copy().T\n", "X /= X.std(axis=0)\n", "edge_model.fit(X)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#############################################################################<br>\n", "Cluster using affinity propagation"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["_, labels = cluster.affinity_propagation(edge_model.covariance_)\n", "n_labels = labels.max()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for i in range(n_labels + 1):\n", "    print('Cluster %i: %s' % ((i + 1), ', '.join(names[labels == i])))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#############################################################################<br>\n", "Find a low-dimension embedding for visualization: find the best position of<br>\n", "the nodes (the stocks) on a 2D plane"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We use a dense eigen_solver to achieve reproducibility (arpack is<br>\n", "initiated with random vectors that we don't control). In addition, we<br>\n", "use a large number of neighbors to capture the large-scale structure."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["node_position_model = manifold.LocallyLinearEmbedding(\n", "    n_components=2, eigen_solver='dense', n_neighbors=6)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["embedding = node_position_model.fit_transform(X.T).T"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#############################################################################<br>\n", "Visualization"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.figure(1, facecolor='w', figsize=(10, 8))\n", "plt.clf()\n", "ax = plt.axes([0., 0., 1., 1.])\n", "plt.axis('off')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Display a graph of the partial correlations"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["partial_correlations = edge_model.precision_.copy()\n", "d = 1 / np.sqrt(np.diag(partial_correlations))\n", "partial_correlations *= d\n", "partial_correlations *= d[:, np.newaxis]\n", "non_zero = (np.abs(np.triu(partial_correlations, k=1)) > 0.02)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Plot the nodes using the coordinates of our embedding"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.scatter(embedding[0], embedding[1], s=100 * d ** 2, c=labels,\n", "            cmap=plt.cm.nipy_spectral)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Plot the edges"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["start_idx, end_idx = np.where(non_zero)\n", "# a sequence of (*line0*, *line1*, *line2*), where::\n", "#            linen = (x0, y0), (x1, y1), ... (xm, ym)\n", "segments = [[embedding[:, start], embedding[:, stop]]\n", "            for start, stop in zip(start_idx, end_idx)]\n", "values = np.abs(partial_correlations[non_zero])\n", "lc = LineCollection(segments,\n", "                    zorder=0, cmap=plt.cm.hot_r,\n", "                    norm=plt.Normalize(0, .7 * values.max()))\n", "lc.set_array(values)\n", "lc.set_linewidths(15 * values)\n", "ax.add_collection(lc)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Add a label to each node. The challenge here is that we want to<br>\n", "position the labels to avoid overlap with other labels"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for index, (name, label, (x, y)) in enumerate(\n", "        zip(names, labels, embedding.T)):\n", "    dx = x - embedding[0]\n", "    dx[index] = 1\n", "    dy = y - embedding[1]\n", "    dy[index] = 1\n", "    this_dx = dx[np.argmin(np.abs(dy))]\n", "    this_dy = dy[np.argmin(np.abs(dx))]\n", "    if this_dx > 0:\n", "        horizontalalignment = 'left'\n", "        x = x + .002\n", "    else:\n", "        horizontalalignment = 'right'\n", "        x = x - .002\n", "    if this_dy > 0:\n", "        verticalalignment = 'bottom'\n", "        y = y + .002\n", "    else:\n", "        verticalalignment = 'top'\n", "        y = y - .002\n", "    plt.text(x, y, name, size=10,\n", "             horizontalalignment=horizontalalignment,\n", "             verticalalignment=verticalalignment,\n", "             bbox=dict(facecolor='w',\n", "                       edgecolor=plt.cm.nipy_spectral(label / float(n_labels)),\n", "                       alpha=.6))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.xlim(embedding[0].min() - .15 * embedding[0].ptp(),\n", "         embedding[0].max() + .10 * embedding[0].ptp(),)\n", "plt.ylim(embedding[1].min() - .03 * embedding[1].ptp(),\n", "         embedding[1].max() + .03 * embedding[1].ptp())"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.show()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}