{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "======================================================<br>\n", "Out-of-core classification of text documents<br>\n", "======================================================<br>\n", "This is an example showing how scikit-learn can be used for classification<br>\n", "using an out-of-core approach: learning from data that doesn't fit into main<br>\n", "memory. We make use of an online classifier, i.e., one that supports the<br>\n", "partial_fit method, that will be fed with batches of examples. To guarantee<br>\n", "that the features space remains the same over time we leverage a<br>\n", "HashingVectorizer that will project each example into the same feature space.<br>\n", "This is especially useful in the case of text classification where new<br>\n", "features (words) may appear in each batch.<br>\n", ""]}, {"cell_type": "markdown", "metadata": {}, "source": ["Authors: Eustache Diemert <eustache@diemert.fr><br>\n", "         @FedericoV <https://github.com/FedericoV/><br>\n", "License: BSD 3 clause"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from glob import glob\n", "import itertools\n", "import os.path\n", "import re\n", "import tarfile\n", "import time\n", "import sys"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "import matplotlib.pyplot as plt\n", "from matplotlib import rcParams"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from html.parser import HTMLParser\n", "from urllib.request import urlretrieve\n", "from sklearn.datasets import get_data_home\n", "from sklearn.feature_extraction.text import HashingVectorizer\n", "from sklearn.linear_model import SGDClassifier\n", "from sklearn.linear_model import PassiveAggressiveClassifier\n", "from sklearn.linear_model import Perceptron\n", "from sklearn.naive_bayes import MultinomialNB"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def _not_in_sphinx():\n", "    # Hack to detect whether we are running by the sphinx builder\n", "    return '__file__' in globals()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#############################################################################<br>\n", "Reuters Dataset related routines<br>\n", "--------------------------------<br>\n", "<br>\n", "The dataset used in this example is Reuters-21578 as provided by the UCI ML<br>\n", "repository. It will be automatically downloaded and uncompressed on first<br>\n", "run."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class ReutersParser(HTMLParser):\n", "    \"\"\"Utility class to parse a SGML file and yield documents one at a time.\"\"\"\n", "    def __init__(self, encoding='latin-1'):\n", "        HTMLParser.__init__(self)\n", "        self._reset()\n", "        self.encoding = encoding\n", "    def handle_starttag(self, tag, attrs):\n", "        method = 'start_' + tag\n", "        getattr(self, method, lambda x: None)(attrs)\n", "    def handle_endtag(self, tag):\n", "        method = 'end_' + tag\n", "        getattr(self, method, lambda: None)()\n", "    def _reset(self):\n", "        self.in_title = 0\n", "        self.in_body = 0\n", "        self.in_topics = 0\n", "        self.in_topic_d = 0\n", "        self.title = \"\"\n", "        self.body = \"\"\n", "        self.topics = []\n", "        self.topic_d = \"\"\n", "    def parse(self, fd):\n", "        self.docs = []\n", "        for chunk in fd:\n", "            self.feed(chunk.decode(self.encoding))\n", "            for doc in self.docs:\n", "                yield doc\n", "            self.docs = []\n", "        self.close()\n", "    def handle_data(self, data):\n", "        if self.in_body:\n", "            self.body += data\n", "        elif self.in_title:\n", "            self.title += data\n", "        elif self.in_topic_d:\n", "            self.topic_d += data\n", "    def start_reuters(self, attributes):\n", "        pass\n", "    def end_reuters(self):\n", "        self.body = re.sub(r'\\s+', r' ', self.body)\n", "        self.docs.append({'title': self.title,\n", "                          'body': self.body,\n", "                          'topics': self.topics})\n", "        self._reset()\n", "    def start_title(self, attributes):\n", "        self.in_title = 1\n", "    def end_title(self):\n", "        self.in_title = 0\n", "    def start_body(self, attributes):\n", "        self.in_body = 1\n", "    def end_body(self):\n", "        self.in_body = 0\n", "    def start_topics(self, attributes):\n", "        self.in_topics = 1\n", "    def end_topics(self):\n", "        self.in_topics = 0\n", "    def start_d(self, attributes):\n", "        self.in_topic_d = 1\n", "    def end_d(self):\n", "        self.in_topic_d = 0\n", "        self.topics.append(self.topic_d)\n", "        self.topic_d = \"\""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def stream_reuters_documents(data_path=None):\n", "    \"\"\"Iterate over documents of the Reuters dataset.\n", "    The Reuters archive will automatically be downloaded and uncompressed if\n", "    the `data_path` directory does not exist.\n", "    Documents are represented as dictionaries with 'body' (str),\n", "    'title' (str), 'topics' (list(str)) keys.\n", "    \"\"\"\n", "    DOWNLOAD_URL = ('http://archive.ics.uci.edu/ml/machine-learning-databases/'\n", "                    'reuters21578-mld/reuters21578.tar.gz')\n", "    ARCHIVE_FILENAME = 'reuters21578.tar.gz'\n", "    if data_path is None:\n", "        data_path = os.path.join(get_data_home(), \"reuters\")\n", "    if not os.path.exists(data_path):\n", "        \"\"\"Download the dataset.\"\"\"\n", "        print(\"downloading dataset (once and for all) into %s\" %\n", "              data_path)\n", "        os.mkdir(data_path)\n", "        def progress(blocknum, bs, size):\n", "            total_sz_mb = '%.2f MB' % (size / 1e6)\n", "            current_sz_mb = '%.2f MB' % ((blocknum * bs) / 1e6)\n", "            if _not_in_sphinx():\n", "                sys.stdout.write(\n", "                    '\\rdownloaded %s / %s' % (current_sz_mb, total_sz_mb))\n", "        archive_path = os.path.join(data_path, ARCHIVE_FILENAME)\n", "        urlretrieve(DOWNLOAD_URL, filename=archive_path,\n", "                    reporthook=progress)\n", "        if _not_in_sphinx():\n", "            sys.stdout.write('\\r')\n", "        print(\"untarring Reuters dataset...\")\n", "        tarfile.open(archive_path, 'r:gz').extractall(data_path)\n", "        print(\"done.\")\n", "    parser = ReutersParser()\n", "    for filename in glob(os.path.join(data_path, \"*.sgm\")):\n", "        for doc in parser.parse(open(filename, 'rb')):\n", "            yield doc"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#############################################################################<br>\n", "Main<br>\n", "----<br>\n", "<br>\n", "Create the vectorizer and limit the number of features to a reasonable<br>\n", "maximum"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["vectorizer = HashingVectorizer(decode_error='ignore', n_features=2 ** 18,\n", "                               alternate_sign=False)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Iterator over parsed Reuters SGML files."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["data_stream = stream_reuters_documents()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We learn a binary classification between the \"acq\" class and all the others.<br>\n", "\"acq\" was chosen as it is more or less evenly distributed in the Reuters<br>\n", "files. For other datasets, one should take care of creating a test set with<br>\n", "a realistic portion of positive instances."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["all_classes = np.array([0, 1])\n", "positive_class = 'acq'"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Here are some classifiers that support the `partial_fit` method"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["partial_fit_classifiers = {\n", "    'SGD': SGDClassifier(max_iter=5),\n", "    'Perceptron': Perceptron(),\n", "    'NB Multinomial': MultinomialNB(alpha=0.01),\n", "    'Passive-Aggressive': PassiveAggressiveClassifier(),\n", "}"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def get_minibatch(doc_iter, size, pos_class=positive_class):\n", "    \"\"\"Extract a minibatch of examples, return a tuple X_text, y.\n", "    Note: size is before excluding invalid docs with no topics assigned.\n", "    \"\"\"\n", "    data = [('{title}\\n\\n{body}'.format(**doc), pos_class in doc['topics'])\n", "            for doc in itertools.islice(doc_iter, size)\n", "            if doc['topics']]\n", "    if not len(data):\n", "        return np.asarray([], dtype=int), np.asarray([], dtype=int)\n", "    X_text, y = zip(*data)\n", "    return X_text, np.asarray(y, dtype=int)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def iter_minibatches(doc_iter, minibatch_size):\n", "    \"\"\"Generator of minibatches.\"\"\"\n", "    X_text, y = get_minibatch(doc_iter, minibatch_size)\n", "    while len(X_text):\n", "        yield X_text, y\n", "        X_text, y = get_minibatch(doc_iter, minibatch_size)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["test data statistics"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["test_stats = {'n_test': 0, 'n_test_pos': 0}"]}, {"cell_type": "markdown", "metadata": {}, "source": ["First we hold out a number of examples to estimate accuracy"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["n_test_documents = 1000\n", "tick = time.time()\n", "X_test_text, y_test = get_minibatch(data_stream, 1000)\n", "parsing_time = time.time() - tick\n", "tick = time.time()\n", "X_test = vectorizer.transform(X_test_text)\n", "vectorizing_time = time.time() - tick\n", "test_stats['n_test'] += len(y_test)\n", "test_stats['n_test_pos'] += sum(y_test)\n", "print(\"Test set is %d documents (%d positive)\" % (len(y_test), sum(y_test)))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def progress(cls_name, stats):\n", "    \"\"\"Report progress information, return a string.\"\"\"\n", "    duration = time.time() - stats['t0']\n", "    s = \"%20s classifier : \\t\" % cls_name\n", "    s += \"%(n_train)6d train docs (%(n_train_pos)6d positive) \" % stats\n", "    s += \"%(n_test)6d test docs (%(n_test_pos)6d positive) \" % test_stats\n", "    s += \"accuracy: %(accuracy).3f \" % stats\n", "    s += \"in %.2fs (%5d docs/s)\" % (duration, stats['n_train'] / duration)\n", "    return s"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["cls_stats = {}"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for cls_name in partial_fit_classifiers:\n", "    stats = {'n_train': 0, 'n_train_pos': 0,\n", "             'accuracy': 0.0, 'accuracy_history': [(0, 0)], 't0': time.time(),\n", "             'runtime_history': [(0, 0)], 'total_fit_time': 0.0}\n", "    cls_stats[cls_name] = stats"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["get_minibatch(data_stream, n_test_documents)\n", "# Discard test set"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We will feed the classifier with mini-batches of 1000 documents; this means<br>\n", "we have at most 1000 docs in memory at any time.  The smaller the document<br>\n", "batch, the bigger the relative overhead of the partial fit methods."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["minibatch_size = 1000"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Create the data_stream that parses Reuters SGML files and iterates on<br>\n", "documents as a stream."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["minibatch_iterators = iter_minibatches(data_stream, minibatch_size)\n", "total_vect_time = 0.0"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Main loop : iterate on mini-batches of examples"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for i, (X_train_text, y_train) in enumerate(minibatch_iterators):\n", "    tick = time.time()\n", "    X_train = vectorizer.transform(X_train_text)\n", "    total_vect_time += time.time() - tick\n", "    for cls_name, cls in partial_fit_classifiers.items():\n", "        tick = time.time()\n", "        # update estimator with examples in the current mini-batch\n", "        cls.partial_fit(X_train, y_train, classes=all_classes)\n\n", "        # accumulate test accuracy stats\n", "        cls_stats[cls_name]['total_fit_time'] += time.time() - tick\n", "        cls_stats[cls_name]['n_train'] += X_train.shape[0]\n", "        cls_stats[cls_name]['n_train_pos'] += sum(y_train)\n", "        tick = time.time()\n", "        cls_stats[cls_name]['accuracy'] = cls.score(X_test, y_test)\n", "        cls_stats[cls_name]['prediction_time'] = time.time() - tick\n", "        acc_history = (cls_stats[cls_name]['accuracy'],\n", "                       cls_stats[cls_name]['n_train'])\n", "        cls_stats[cls_name]['accuracy_history'].append(acc_history)\n", "        run_history = (cls_stats[cls_name]['accuracy'],\n", "                       total_vect_time + cls_stats[cls_name]['total_fit_time'])\n", "        cls_stats[cls_name]['runtime_history'].append(run_history)\n", "        if i % 3 == 0:\n", "            print(progress(cls_name, cls_stats[cls_name]))\n", "    if i % 3 == 0:\n", "        print('\\n')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#############################################################################<br>\n", "Plot results<br>\n", "------------<br>\n", "<br>\n", "The plot represents the learning curve of the classifier: the evolution<br>\n", "of classification accuracy over the course of the mini-batches. Accuracy is<br>\n", "measured on the first 1000 samples, held out as a validation set.<br>\n", "<br>\n", "To limit the memory consumption, we queue examples up to a fixed amount<br>\n", "before feeding them to the learner."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def plot_accuracy(x, y, x_legend):\n", "    \"\"\"Plot accuracy as a function of x.\"\"\"\n", "    x = np.array(x)\n", "    y = np.array(y)\n", "    plt.title('Classification accuracy as a function of %s' % x_legend)\n", "    plt.xlabel('%s' % x_legend)\n", "    plt.ylabel('Accuracy')\n", "    plt.grid(True)\n", "    plt.plot(x, y)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["rcParams['legend.fontsize'] = 10\n", "cls_names = list(sorted(cls_stats.keys()))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Plot accuracy evolution"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.figure()\n", "for _, stats in sorted(cls_stats.items()):\n", "    # Plot accuracy evolution with #examples\n", "    accuracy, n_examples = zip(*stats['accuracy_history'])\n", "    plot_accuracy(n_examples, accuracy, \"training examples (#)\")\n", "    ax = plt.gca()\n", "    ax.set_ylim((0.8, 1))\n", "plt.legend(cls_names, loc='best')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.figure()\n", "for _, stats in sorted(cls_stats.items()):\n", "    # Plot accuracy evolution with runtime\n", "    accuracy, runtime = zip(*stats['runtime_history'])\n", "    plot_accuracy(runtime, accuracy, 'runtime (s)')\n", "    ax = plt.gca()\n", "    ax.set_ylim((0.8, 1))\n", "plt.legend(cls_names, loc='best')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Plot fitting times"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.figure()\n", "fig = plt.gcf()\n", "cls_runtime = [stats['total_fit_time']\n", "               for cls_name, stats in sorted(cls_stats.items())]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["cls_runtime.append(total_vect_time)\n", "cls_names.append('Vectorization')\n", "bar_colors = ['b', 'g', 'r', 'c', 'm', 'y']"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["ax = plt.subplot(111)\n", "rectangles = plt.bar(range(len(cls_names)), cls_runtime, width=0.5,\n", "                     color=bar_colors)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["ax.set_xticks(np.linspace(0, len(cls_names) - 1, len(cls_names)))\n", "ax.set_xticklabels(cls_names, fontsize=10)\n", "ymax = max(cls_runtime) * 1.2\n", "ax.set_ylim((0, ymax))\n", "ax.set_ylabel('runtime (s)')\n", "ax.set_title('Training Times')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def autolabel(rectangles):\n", "    \"\"\"attach some text vi autolabel on rectangles.\"\"\"\n", "    for rect in rectangles:\n", "        height = rect.get_height()\n", "        ax.text(rect.get_x() + rect.get_width() / 2.,\n", "                1.05 * height, '%.4f' % height,\n", "                ha='center', va='bottom')\n", "        plt.setp(plt.xticks()[1], rotation=30)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["autolabel(rectangles)\n", "plt.tight_layout()\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Plot prediction times"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.figure()\n", "cls_runtime = []\n", "cls_names = list(sorted(cls_stats.keys()))\n", "for cls_name, stats in sorted(cls_stats.items()):\n", "    cls_runtime.append(stats['prediction_time'])\n", "cls_runtime.append(parsing_time)\n", "cls_names.append('Read/Parse\\n+Feat.Extr.')\n", "cls_runtime.append(vectorizing_time)\n", "cls_names.append('Hashing\\n+Vect.')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["ax = plt.subplot(111)\n", "rectangles = plt.bar(range(len(cls_names)), cls_runtime, width=0.5,\n", "                     color=bar_colors)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["ax.set_xticks(np.linspace(0, len(cls_names) - 1, len(cls_names)))\n", "ax.set_xticklabels(cls_names, fontsize=8)\n", "plt.setp(plt.xticks()[1], rotation=30)\n", "ymax = max(cls_runtime) * 1.2\n", "ax.set_ylim((0, ymax))\n", "ax.set_ylabel('runtime (s)')\n", "ax.set_title('Prediction Times (%d instances)' % n_test_documents)\n", "autolabel(rectangles)\n", "plt.tight_layout()\n", "plt.show()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}