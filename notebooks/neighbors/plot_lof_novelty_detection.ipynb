{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "=================================================<br>\n", "Novelty detection with Local Outlier Factor (LOF)<br>\n", "=================================================<br>\n", "The Local Outlier Factor (LOF) algorithm is an unsupervised anomaly detection<br>\n", "method which computes the local density deviation of a given data point with<br>\n", "respect to its neighbors. It considers as outliers the samples that have a<br>\n", "substantially lower density than their neighbors. This example shows how to<br>\n", "use LOF for novelty detection. Note that when LOF is used for novelty<br>\n", "detection you MUST not use predict, decision_function and score_samples on the<br>\n", "training set as this would lead to wrong results. You must only use these<br>\n", "methods on new unseen data (which are not in the training set). See<br>\n", ":ref:`User Guide <outlier_detection>`: for details on the difference between<br>\n", "outlier detection and novelty detection and how to use LOF for outlier<br>\n", "detection.<br>\n", "The number of neighbors considered, (parameter n_neighbors) is typically<br>\n", "set 1) greater than the minimum number of samples a cluster has to contain,<br>\n", "so that other samples can be local outliers relative to this cluster, and 2)<br>\n", "smaller than the maximum number of close by samples that can potentially be<br>\n", "local outliers.<br>\n", "In practice, such informations are generally not available, and taking<br>\n", "n_neighbors=20 appears to work well in general.<br>\n", ""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "import matplotlib\n", "import matplotlib.pyplot as plt\n", "from sklearn.neighbors import LocalOutlierFactor"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(__doc__)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["np.random.seed(42)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["xx, yy = np.meshgrid(np.linspace(-5, 5, 500), np.linspace(-5, 5, 500))\n", "# Generate normal (not abnormal) training observations\n", "X = 0.3 * np.random.randn(100, 2)\n", "X_train = np.r_[X + 2, X - 2]\n", "# Generate new normal (not abnormal) observations\n", "X = 0.3 * np.random.randn(20, 2)\n", "X_test = np.r_[X + 2, X - 2]\n", "# Generate some abnormal novel observations\n", "X_outliers = np.random.uniform(low=-4, high=4, size=(20, 2))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["fit the model for novelty detection (novelty=True)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["clf = LocalOutlierFactor(n_neighbors=20, novelty=True, contamination=0.1)\n", "clf.fit(X_train)\n", "# DO NOT use predict, decision_function and score_samples on X_train as this\n", "# would give wrong results but only on new unseen data (not used in X_train),\n", "# e.g. X_test, X_outliers or the meshgrid\n", "y_pred_test = clf.predict(X_test)\n", "y_pred_outliers = clf.predict(X_outliers)\n", "n_error_test = y_pred_test[y_pred_test == -1].size\n", "n_error_outliers = y_pred_outliers[y_pred_outliers == 1].size"]}, {"cell_type": "markdown", "metadata": {}, "source": ["plot the learned frontier, the points, and the nearest vectors to the plane"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\n", "Z = Z.reshape(xx.shape)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.title(\"Novelty Detection with LOF\")\n", "plt.contourf(xx, yy, Z, levels=np.linspace(Z.min(), 0, 7), cmap=plt.cm.PuBu)\n", "a = plt.contour(xx, yy, Z, levels=[0], linewidths=2, colors='darkred')\n", "plt.contourf(xx, yy, Z, levels=[0, Z.max()], colors='palevioletred')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["s = 40\n", "b1 = plt.scatter(X_train[:, 0], X_train[:, 1], c='white', s=s, edgecolors='k')\n", "b2 = plt.scatter(X_test[:, 0], X_test[:, 1], c='blueviolet', s=s,\n", "                 edgecolors='k')\n", "c = plt.scatter(X_outliers[:, 0], X_outliers[:, 1], c='gold', s=s,\n", "                edgecolors='k')\n", "plt.axis('tight')\n", "plt.xlim((-5, 5))\n", "plt.ylim((-5, 5))\n", "plt.legend([a.collections[0], b1, b2, c],\n", "           [\"learned frontier\", \"training observations\",\n", "            \"new regular observations\", \"new abnormal observations\"],\n", "           loc=\"upper left\",\n", "           prop=matplotlib.font_manager.FontProperties(size=11))\n", "plt.xlabel(\n", "    \"errors novel regular: %d/40 ; errors novel abnormal: %d/40\"\n", "    % (n_error_test, n_error_outliers))\n", "plt.show()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}