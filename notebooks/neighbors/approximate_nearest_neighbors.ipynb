{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "=====================================<br>\n", "Approximate nearest neighbors in TSNE<br>\n", "=====================================<br>\n", "This example presents how to chain KNeighborsTransformer and TSNE in a<br>\n", "pipeline. It also shows how to wrap the packages `annoy` and `nmslib` to<br>\n", "replace KNeighborsTransformer and perform approximate nearest neighbors.<br>\n", "These packages can be installed with `pip install annoy nmslib`.<br>\n", "Note: Currently `TSNE(metric='precomputed')` does not modify the precomputed<br>\n", "distances, and thus assumes that precomputed euclidean distances are squared.<br>\n", "In future versions, a parameter in TSNE will control the optional squaring of<br>\n", "precomputed distances (see #12401).<br>\n", "Note: In KNeighborsTransformer we use the definition which includes each<br>\n", "training point as its own neighbor in the count of `n_neighbors`, and for<br>\n", "compatibility reasons, one extra neighbor is computed when<br>\n", "`mode == 'distance'`. Please note that we do the same in the proposed wrappers.<br>\n", "Sample output::<br>\n", "    Benchmarking on MNIST_2000:<br>\n", "    ---------------------------<br>\n", "    AnnoyTransformer:                    0.583 sec<br>\n", "    NMSlibTransformer:                   0.321 sec<br>\n", "    KNeighborsTransformer:               1.225 sec<br>\n", "    TSNE with AnnoyTransformer:          4.903 sec<br>\n", "    TSNE with NMSlibTransformer:         5.009 sec<br>\n", "    TSNE with KNeighborsTransformer:     6.210 sec<br>\n", "    TSNE with internal NearestNeighbors: 6.365 sec<br>\n", "    Benchmarking on MNIST_10000:<br>\n", "    ----------------------------<br>\n", "    AnnoyTransformer:                    4.457 sec<br>\n", "    NMSlibTransformer:                   2.080 sec<br>\n", "    KNeighborsTransformer:               30.680 sec<br>\n", "    TSNE with AnnoyTransformer:          30.225 sec<br>\n", "    TSNE with NMSlibTransformer:         43.295 sec<br>\n", "    TSNE with KNeighborsTransformer:     64.845 sec<br>\n", "    TSNE with internal NearestNeighbors: 64.984 sec<br>\n", "<br>\n", "Author: Tom Dupre la Tour<br>\n", "<br>\n", "License: BSD 3 clause"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import time\n", "import sys"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["try:\n", "    import annoy\n", "except ImportError:\n", "    print(\"The package 'annoy' is required to run this example.\")\n", "    sys.exit()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["try:\n", "    import nmslib\n", "except ImportError:\n", "    print(\"The package 'nmslib' is required to run this example.\")\n", "    sys.exit()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "import matplotlib.pyplot as plt\n", "from matplotlib.ticker import NullFormatter\n", "from scipy.sparse import csr_matrix"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.base import BaseEstimator, TransformerMixin\n", "from sklearn.neighbors import KNeighborsTransformer\n", "from sklearn.utils._testing import assert_array_almost_equal\n", "from sklearn.datasets import fetch_openml\n", "from sklearn.pipeline import make_pipeline\n", "from sklearn.manifold import TSNE\n", "from sklearn.utils import shuffle"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(__doc__)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class NMSlibTransformer(TransformerMixin, BaseEstimator):\n", "    \"\"\"Wrapper for using nmslib as sklearn's KNeighborsTransformer\"\"\"\n", "    def __init__(self, n_neighbors=5, metric='euclidean', method='sw-graph',\n", "                 n_jobs=1):\n", "        self.n_neighbors = n_neighbors\n", "        self.method = method\n", "        self.metric = metric\n", "        self.n_jobs = n_jobs\n", "    def fit(self, X):\n", "        self.n_samples_fit_ = X.shape[0]\n\n", "        # see more metric in the manual\n", "        # https://github.com/nmslib/nmslib/tree/master/manual\n", "        space = {\n", "            'sqeuclidean': 'l2',\n", "            'euclidean': 'l2',\n", "            'cosine': 'cosinesimil',\n", "            'l1': 'l1',\n", "            'l2': 'l2',\n", "        }[self.metric]\n", "        self.nmslib_ = nmslib.init(method=self.method, space=space)\n", "        self.nmslib_.addDataPointBatch(X)\n", "        self.nmslib_.createIndex()\n", "        return self\n", "    def transform(self, X):\n", "        n_samples_transform = X.shape[0]\n\n", "        # For compatibility reasons, as each sample is considered as its own\n", "        # neighbor, one extra neighbor will be computed.\n", "        n_neighbors = self.n_neighbors + 1\n", "        results = self.nmslib_.knnQueryBatch(X, k=n_neighbors,\n", "                                             num_threads=self.n_jobs)\n", "        indices, distances = zip(*results)\n", "        indices, distances = np.vstack(indices), np.vstack(distances)\n", "        if self.metric == 'sqeuclidean':\n", "            distances **= 2\n", "        indptr = np.arange(0, n_samples_transform * n_neighbors + 1,\n", "                           n_neighbors)\n", "        kneighbors_graph = csr_matrix((distances.ravel(), indices.ravel(),\n", "                                       indptr), shape=(n_samples_transform,\n", "                                                       self.n_samples_fit_))\n", "        return kneighbors_graph"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class AnnoyTransformer(TransformerMixin, BaseEstimator):\n", "    \"\"\"Wrapper for using annoy.AnnoyIndex as sklearn's KNeighborsTransformer\"\"\"\n", "    def __init__(self, n_neighbors=5, metric='euclidean', n_trees=10,\n", "                 search_k=-1):\n", "        self.n_neighbors = n_neighbors\n", "        self.n_trees = n_trees\n", "        self.search_k = search_k\n", "        self.metric = metric\n", "    def fit(self, X):\n", "        self.n_samples_fit_ = X.shape[0]\n", "        metric = self.metric if self.metric != 'sqeuclidean' else 'euclidean'\n", "        self.annoy_ = annoy.AnnoyIndex(X.shape[1], metric=metric)\n", "        for i, x in enumerate(X):\n", "            self.annoy_.add_item(i, x.tolist())\n", "        self.annoy_.build(self.n_trees)\n", "        return self\n", "    def transform(self, X):\n", "        return self._transform(X)\n", "    def fit_transform(self, X, y=None):\n", "        return self.fit(X)._transform(X=None)\n", "    def _transform(self, X):\n", "        \"\"\"As `transform`, but handles X is None for faster `fit_transform`.\"\"\"\n", "        n_samples_transform = self.n_samples_fit_ if X is None else X.shape[0]\n\n", "        # For compatibility reasons, as each sample is considered as its own\n", "        # neighbor, one extra neighbor will be computed.\n", "        n_neighbors = self.n_neighbors + 1\n", "        indices = np.empty((n_samples_transform, n_neighbors),\n", "                           dtype=np.int)\n", "        distances = np.empty((n_samples_transform, n_neighbors))\n", "        if X is None:\n", "            for i in range(self.annoy_.get_n_items()):\n", "                ind, dist = self.annoy_.get_nns_by_item(\n", "                    i, n_neighbors, self.search_k, include_distances=True)\n", "                indices[i], distances[i] = ind, dist\n", "        else:\n", "            for i, x in enumerate(X):\n", "                indices[i], distances[i] = self.annoy_.get_nns_by_vector(\n", "                    x.tolist(), n_neighbors, self.search_k,\n", "                    include_distances=True)\n", "        if self.metric == 'sqeuclidean':\n", "            distances **= 2\n", "        indptr = np.arange(0, n_samples_transform * n_neighbors + 1,\n", "                           n_neighbors)\n", "        kneighbors_graph = csr_matrix((distances.ravel(), indices.ravel(),\n", "                                       indptr), shape=(n_samples_transform,\n", "                                                       self.n_samples_fit_))\n", "        return kneighbors_graph"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def test_transformers():\n", "    \"\"\"Test that AnnoyTransformer and KNeighborsTransformer give same results\n", "    \"\"\"\n", "    X = np.random.RandomState(42).randn(10, 2)\n", "    knn = KNeighborsTransformer()\n", "    Xt0 = knn.fit_transform(X)\n", "    ann = AnnoyTransformer()\n", "    Xt1 = ann.fit_transform(X)\n", "    nms = NMSlibTransformer()\n", "    Xt2 = nms.fit_transform(X)\n", "    assert_array_almost_equal(Xt0.toarray(), Xt1.toarray(), decimal=5)\n", "    assert_array_almost_equal(Xt0.toarray(), Xt2.toarray(), decimal=5)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def load_mnist(n_samples):\n", "    \"\"\"Load MNIST, shuffle the data, and return only n_samples.\"\"\"\n", "    mnist = fetch_openml(data_id=41063)\n", "    X, y = shuffle(mnist.data, mnist.target, random_state=42)\n", "    return X[:n_samples], y[:n_samples]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def run_benchmark():\n", "    datasets = [\n", "        ('MNIST_2000', load_mnist(n_samples=2000)),\n", "        ('MNIST_10000', load_mnist(n_samples=10000)),\n", "    ]\n", "    n_iter = 500\n", "    perplexity = 30\n", "    # TSNE requires a certain number of neighbors which depends on the\n", "    # perplexity parameter.\n", "    # Add one since we include each sample as its own neighbor.\n", "    n_neighbors = int(3. * perplexity + 1) + 1\n", "    transformers = [\n", "        ('AnnoyTransformer', AnnoyTransformer(n_neighbors=n_neighbors,\n", "                                              metric='sqeuclidean')),\n", "        ('NMSlibTransformer', NMSlibTransformer(n_neighbors=n_neighbors,\n", "                                                metric='sqeuclidean')),\n", "        ('KNeighborsTransformer', KNeighborsTransformer(\n", "            n_neighbors=n_neighbors, mode='distance', metric='sqeuclidean')),\n", "        ('TSNE with AnnoyTransformer', make_pipeline(\n", "            AnnoyTransformer(n_neighbors=n_neighbors, metric='sqeuclidean'),\n", "            TSNE(metric='precomputed', perplexity=perplexity,\n", "                 method=\"barnes_hut\", random_state=42, n_iter=n_iter), )),\n", "        ('TSNE with NMSlibTransformer', make_pipeline(\n", "            NMSlibTransformer(n_neighbors=n_neighbors, metric='sqeuclidean'),\n", "            TSNE(metric='precomputed', perplexity=perplexity,\n", "                 method=\"barnes_hut\", random_state=42, n_iter=n_iter), )),\n", "        ('TSNE with KNeighborsTransformer', make_pipeline(\n", "            KNeighborsTransformer(n_neighbors=n_neighbors, mode='distance',\n", "                                  metric='sqeuclidean'),\n", "            TSNE(metric='precomputed', perplexity=perplexity,\n", "                 method=\"barnes_hut\", random_state=42, n_iter=n_iter), )),\n", "        ('TSNE with internal NearestNeighbors',\n", "         TSNE(metric='sqeuclidean', perplexity=perplexity, method=\"barnes_hut\",\n", "              random_state=42, n_iter=n_iter)),\n", "    ]\n\n", "    # init the plot\n", "    nrows = len(datasets)\n", "    ncols = np.sum([1 for name, model in transformers if 'TSNE' in name])\n", "    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, squeeze=False,\n", "                             figsize=(5 * ncols, 4 * nrows))\n", "    axes = axes.ravel()\n", "    i_ax = 0\n", "    for dataset_name, (X, y) in datasets:\n", "        msg = 'Benchmarking on %s:' % dataset_name\n", "        print('\\n%s\\n%s' % (msg, '-' * len(msg)))\n", "        for transformer_name, transformer in transformers:\n", "            start = time.time()\n", "            Xt = transformer.fit_transform(X)\n", "            duration = time.time() - start\n\n", "            # print the duration report\n", "            longest = np.max([len(name) for name, model in transformers])\n", "            whitespaces = ' ' * (longest - len(transformer_name))\n", "            print('%s: %s%.3f sec' % (transformer_name, whitespaces, duration))\n\n", "            # plot TSNE embedding which should be very similar across methods\n", "            if 'TSNE' in transformer_name:\n", "                axes[i_ax].set_title(transformer_name + '\\non ' + dataset_name)\n", "                axes[i_ax].scatter(Xt[:, 0], Xt[:, 1], c=y, alpha=0.2,\n", "                                   cmap=plt.cm.viridis)\n", "                axes[i_ax].xaxis.set_major_formatter(NullFormatter())\n", "                axes[i_ax].yaxis.set_major_formatter(NullFormatter())\n", "                axes[i_ax].axis('tight')\n", "                i_ax += 1\n", "    fig.tight_layout()\n", "    plt.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if __name__ == '__main__':\n", "    test_transformers()\n", "    run_benchmark()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}