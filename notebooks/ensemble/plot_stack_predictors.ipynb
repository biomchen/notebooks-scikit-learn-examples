{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "=================================<br>\n", "Combine predictors using stacking<br>\n", "=================================<br>\n", "Stacking refers to a method to blend estimators. In this strategy, some<br>\n", "estimators are individually fitted on some training data while a final<br>\n", "estimator is trained using the stacked predictions of these base estimators.<br>\n", "In this example, we illustrate the use case in which different regressors are<br>\n", "stacked together and a final linear penalized regressor is used to output the<br>\n", "prediction. We compare the performance of each individual regressor with the<br>\n", "stacking strategy. Stacking slightly improves the overall performance.<br>\n", ""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(__doc__)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Authors: Guillaume Lemaitre <g.lemaitre58@gmail.com><br>\n", "License: BSD 3 clause"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#############################################################################<br>\n", "The function ``plot_regression_results`` is used to plot the predicted and<br>\n", "true targets."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import matplotlib.pyplot as plt"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def plot_regression_results(ax, y_true, y_pred, title, scores, elapsed_time):\n", "    \"\"\"Scatter plot of the predicted vs true targets.\"\"\"\n", "    ax.plot([y_true.min(), y_true.max()],\n", "            [y_true.min(), y_true.max()],\n", "            '--r', linewidth=2)\n", "    ax.scatter(y_true, y_pred, alpha=0.2)\n", "    ax.spines['top'].set_visible(False)\n", "    ax.spines['right'].set_visible(False)\n", "    ax.get_xaxis().tick_bottom()\n", "    ax.get_yaxis().tick_left()\n", "    ax.spines['left'].set_position(('outward', 10))\n", "    ax.spines['bottom'].set_position(('outward', 10))\n", "    ax.set_xlim([y_true.min(), y_true.max()])\n", "    ax.set_ylim([y_true.min(), y_true.max()])\n", "    ax.set_xlabel('Measured')\n", "    ax.set_ylabel('Predicted')\n", "    extra = plt.Rectangle((0, 0), 0, 0, fc=\"w\", fill=False,\n", "                          edgecolor='none', linewidth=0)\n", "    ax.legend([extra], [scores], loc='upper left')\n", "    title = title + '\\n Evaluation in {:.2f} seconds'.format(elapsed_time)\n", "    ax.set_title(title)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#############################################################################<br>\n", "Stack of predictors on a single data set<br>\n", "#############################################################################<br>\n", "It is sometimes tedious to find the model which will best perform on a given<br>\n", "dataset. Stacking provide an alternative by combining the outputs of several<br>\n", "learners, without the need to choose a model specifically. The performance of<br>\n", "stacking is usually close to the best model and sometimes it can outperform<br>\n", "the prediction performance of each individual model.<br>\n", "<br>\n", "Here, we combine 3 learners (linear and non-linear) and use a ridge regressor<br>\n", "to combine their outputs together."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.ensemble import StackingRegressor\n", "from sklearn.ensemble import RandomForestRegressor\n", "from sklearn.experimental import enable_hist_gradient_boosting  # noqa\n", "from sklearn.ensemble import HistGradientBoostingRegressor\n", "from sklearn.linear_model import LassoCV\n", "from sklearn.linear_model import RidgeCV"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["estimators = [\n", "    ('Random Forest', RandomForestRegressor(random_state=42)),\n", "    ('Lasso', LassoCV()),\n", "    ('Gradient Boosting', HistGradientBoostingRegressor(random_state=0))\n", "]\n", "stacking_regressor = StackingRegressor(\n", "    estimators=estimators, final_estimator=RidgeCV()\n", ")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#############################################################################<br>\n", "We used the Boston data set (prediction of house prices). We check the<br>\n", "performance of each individual predictor as well as the stack of the<br>\n", "regressors."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import time\n", "import numpy as np\n", "from sklearn.datasets import load_boston\n", "from sklearn.model_selection import cross_validate, cross_val_predict"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X, y = load_boston(return_X_y=True)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fig, axs = plt.subplots(2, 2, figsize=(9, 7))\n", "axs = np.ravel(axs)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for ax, (name, est) in zip(axs, estimators + [('Stacking Regressor',\n", "                                               stacking_regressor)]):\n", "    start_time = time.time()\n", "    score = cross_validate(est, X, y,\n", "                           scoring=['r2', 'neg_mean_absolute_error'],\n", "                           n_jobs=-1, verbose=0)\n", "    elapsed_time = time.time() - start_time\n", "    y_pred = cross_val_predict(est, X, y, n_jobs=-1, verbose=0)\n", "    plot_regression_results(\n", "        ax, y, y_pred,\n", "        name,\n", "        (r'$R^2={:.2f} \\pm {:.2f}$' + '\\n' + r'$MAE={:.2f} \\pm {:.2f}$')\n", "        .format(np.mean(score['test_r2']),\n", "                np.std(score['test_r2']),\n", "                -np.mean(score['test_neg_mean_absolute_error']),\n", "                np.std(score['test_neg_mean_absolute_error'])),\n", "        elapsed_time)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.suptitle('Single predictors versus stacked predictors')\n", "plt.tight_layout()\n", "plt.subplots_adjust(top=0.9)\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#############################################################################<br>\n", "The stacked regressor will combine the strengths of the different regressors.<br>\n", "However, we also see that training the stacked regressor is much more<br>\n", "computationally expensive."]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}