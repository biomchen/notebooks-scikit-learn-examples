{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "===================================<br>\n", "Early stopping of Gradient Boosting<br>\n", "===================================<br>\n", "Gradient boosting is an ensembling technique where several weak learners<br>\n", "(regression trees) are combined to yield a powerful single model, in an<br>\n", "iterative fashion.<br>\n", "Early stopping support in Gradient Boosting enables us to find the least number<br>\n", "of iterations which is sufficient to build a model that generalizes well to<br>\n", "unseen data.<br>\n", "The concept of early stopping is simple. We specify a ``validation_fraction``<br>\n", "which denotes the fraction of the whole dataset that will be kept aside from<br>\n", "training to assess the validation loss of the model. The gradient boosting<br>\n", "model is trained using the training set and evaluated using the validation set.<br>\n", "When each additional stage of regression tree is added, the validation set is<br>\n", "used to score the model.  This is continued until the scores of the model in<br>\n", "the last ``n_iter_no_change`` stages do not improve by atleast `tol`. After<br>\n", "that the model is considered to have converged and further addition of stages<br>\n", "is \"stopped early\".<br>\n", "The number of stages of the final model is available at the attribute<br>\n", "``n_estimators_``.<br>\n", "This example illustrates how the early stopping can used in the<br>\n", ":class:`sklearn.ensemble.GradientBoostingClassifier` model to achieve<br>\n", "almost the same accuracy as compared to a model built without early stopping<br>\n", "using many fewer estimators. This can significantly reduce training time,<br>\n", "memory usage and prediction latency.<br>\n", ""]}, {"cell_type": "markdown", "metadata": {}, "source": ["Authors: Vighnesh Birodkar <vighneshbirodkar@nyu.edu><br>\n", "         Raghav RV <rvraghav93@gmail.com><br>\n", "License: BSD 3 clause"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import time"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "import matplotlib.pyplot as plt"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn import ensemble\n", "from sklearn import datasets\n", "from sklearn.model_selection import train_test_split"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(__doc__)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["data_list = [datasets.load_iris(), datasets.load_digits()]\n", "data_list = [(d.data, d.target) for d in data_list]\n", "data_list += [datasets.make_hastie_10_2()]\n", "names = ['Iris Data', 'Digits Data', 'Hastie Data']"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["n_gb = []\n", "score_gb = []\n", "time_gb = []\n", "n_gbes = []\n", "score_gbes = []\n", "time_gbes = []"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["n_estimators = 500"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for X, y in data_list:\n", "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n", "                                                        random_state=0)\n\n", "    # We specify that if the scores don't improve by atleast 0.01 for the last\n", "    # 10 stages, stop fitting additional stages\n", "    gbes = ensemble.GradientBoostingClassifier(n_estimators=n_estimators,\n", "                                               validation_fraction=0.2,\n", "                                               n_iter_no_change=5, tol=0.01,\n", "                                               random_state=0)\n", "    gb = ensemble.GradientBoostingClassifier(n_estimators=n_estimators,\n", "                                             random_state=0)\n", "    start = time.time()\n", "    gb.fit(X_train, y_train)\n", "    time_gb.append(time.time() - start)\n", "    start = time.time()\n", "    gbes.fit(X_train, y_train)\n", "    time_gbes.append(time.time() - start)\n", "    score_gb.append(gb.score(X_test, y_test))\n", "    score_gbes.append(gbes.score(X_test, y_test))\n", "    n_gb.append(gb.n_estimators_)\n", "    n_gbes.append(gbes.n_estimators_)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["bar_width = 0.2\n", "n = len(data_list)\n", "index = np.arange(0, n * bar_width, bar_width) * 2.5\n", "index = index[0:n]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#####################################################################<br>\n", "Compare scores with and without early stopping<br>\n", "----------------------------------------------"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(9, 5))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["bar1 = plt.bar(index, score_gb, bar_width, label='Without early stopping',\n", "               color='crimson')\n", "bar2 = plt.bar(index + bar_width, score_gbes, bar_width,\n", "               label='With early stopping', color='coral')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.xticks(index + bar_width, names)\n", "plt.yticks(np.arange(0, 1.3, 0.1))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def autolabel(rects, n_estimators):\n", "    \"\"\"\n", "    Attach a text label above each bar displaying n_estimators of each model\n", "    \"\"\"\n", "    for i, rect in enumerate(rects):\n", "        plt.text(rect.get_x() + rect.get_width() / 2.,\n", "                 1.05 * rect.get_height(), 'n_est=%d' % n_estimators[i],\n", "                 ha='center', va='bottom')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["autolabel(bar1, n_gb)\n", "autolabel(bar2, n_gbes)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.ylim([0, 1.3])\n", "plt.legend(loc='best')\n", "plt.grid(True)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.xlabel('Datasets')\n", "plt.ylabel('Test score')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#####################################################################<br>\n", "Compare fit times with and without early stopping<br>\n", "-------------------------------------------------"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(9, 5))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["bar1 = plt.bar(index, time_gb, bar_width, label='Without early stopping',\n", "               color='crimson')\n", "bar2 = plt.bar(index + bar_width, time_gbes, bar_width,\n", "               label='With early stopping', color='coral')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["max_y = np.amax(np.maximum(time_gb, time_gbes))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.xticks(index + bar_width, names)\n", "plt.yticks(np.linspace(0, 1.3 * max_y, 13))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["autolabel(bar1, n_gb)\n", "autolabel(bar2, n_gbes)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.ylim([0, 1.3 * max_y])\n", "plt.legend(loc='best')\n", "plt.grid(True)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.xlabel('Datasets')\n", "plt.ylabel('Fit Time')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.show()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}