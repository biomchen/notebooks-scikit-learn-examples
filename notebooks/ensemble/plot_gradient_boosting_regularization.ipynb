{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "================================<br>\n", "Gradient Boosting regularization<br>\n", "================================<br>\n", "Illustration of the effect of different regularization strategies<br>\n", "for Gradient Boosting. The example is taken from Hastie et al 2009 [1]_.<br>\n", "The loss function used is binomial deviance. Regularization via<br>\n", "shrinkage (``learning_rate < 1.0``) improves performance considerably.<br>\n", "In combination with shrinkage, stochastic gradient boosting<br>\n", "(``subsample < 1.0``) can produce more accurate models by reducing the<br>\n", "variance via bagging.<br>\n", "Subsampling without shrinkage usually does poorly.<br>\n", "Another strategy to reduce the variance is by subsampling the features<br>\n", "analogous to the random splits in Random Forests<br>\n", "(via the ``max_features`` parameter).<br>\n", ".. [1] T. Hastie, R. Tibshirani and J. Friedman, \"Elements of Statistical<br>\n", "    Learning Ed. 2\", Springer, 2009.<br>\n", ""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(__doc__)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Author: Peter Prettenhofer <peter.prettenhofer@gmail.com><br>\n", "<br>\n", "License: BSD 3 clause"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "import matplotlib.pyplot as plt"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn import ensemble\n", "from sklearn import datasets"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X, y = datasets.make_hastie_10_2(n_samples=12000, random_state=1)\n", "X = X.astype(np.float32)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["map labels from {-1, 1} to {0, 1}"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["labels, y = np.unique(y, return_inverse=True)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X_train, X_test = X[:2000], X[2000:]\n", "y_train, y_test = y[:2000], y[2000:]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["original_params = {'n_estimators': 1000, 'max_leaf_nodes': 4, 'max_depth': None, 'random_state': 2,\n", "                   'min_samples_split': 5}"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.figure()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for label, color, setting in [('No shrinkage', 'orange',\n", "                               {'learning_rate': 1.0, 'subsample': 1.0}),\n", "                              ('learning_rate=0.1', 'turquoise',\n", "                               {'learning_rate': 0.1, 'subsample': 1.0}),\n", "                              ('subsample=0.5', 'blue',\n", "                               {'learning_rate': 1.0, 'subsample': 0.5}),\n", "                              ('learning_rate=0.1, subsample=0.5', 'gray',\n", "                               {'learning_rate': 0.1, 'subsample': 0.5}),\n", "                              ('learning_rate=0.1, max_features=2', 'magenta',\n", "                               {'learning_rate': 0.1, 'max_features': 2})]:\n", "    params = dict(original_params)\n", "    params.update(setting)\n", "    clf = ensemble.GradientBoostingClassifier(**params)\n", "    clf.fit(X_train, y_train)\n\n", "    # compute test set deviance\n", "    test_deviance = np.zeros((params['n_estimators'],), dtype=np.float64)\n", "    for i, y_pred in enumerate(clf.staged_decision_function(X_test)):\n", "        # clf.loss_ assumes that y_test[i] in {0, 1}\n", "        test_deviance[i] = clf.loss_(y_test, y_pred)\n", "    plt.plot((np.arange(test_deviance.shape[0]) + 1)[::5], test_deviance[::5],\n", "            '-', color=color, label=label)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.legend(loc='upper left')\n", "plt.xlabel('Boosting Iterations')\n", "plt.ylabel('Test Set Deviance')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.show()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}