{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "===============================================<br>\n", "Feature transformations with ensembles of trees<br>\n", "===============================================<br>\n", "Transform your features into a higher dimensional, sparse space. Then<br>\n", "train a linear model on these features.<br>\n", "First fit an ensemble of trees (totally random trees, a random<br>\n", "forest, or gradient boosted trees) on the training set. Then each leaf<br>\n", "of each tree in the ensemble is assigned a fixed arbitrary feature<br>\n", "index in a new feature space. These leaf indices are then encoded in a<br>\n", "one-hot fashion.<br>\n", "Each sample goes through the decisions of each tree of the ensemble<br>\n", "and ends up in one leaf per tree. The sample is encoded by setting<br>\n", "feature values for these leaves to 1 and the other feature values to 0.<br>\n", "The resulting transformer has then learned a supervised, sparse,<br>\n", "high-dimensional categorical embedding of the data.<br>\n", ""]}, {"cell_type": "markdown", "metadata": {}, "source": ["Author: Tim Head <betatim@gmail.com><br>\n", "<br>\n", "License: BSD 3 clause"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "np.random.seed(10)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import matplotlib.pyplot as plt"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.datasets import make_classification\n", "from sklearn.linear_model import LogisticRegression\n", "from sklearn.ensemble import (RandomTreesEmbedding, RandomForestClassifier,\n", "                              GradientBoostingClassifier)\n", "from sklearn.preprocessing import OneHotEncoder\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.metrics import roc_curve\n", "from sklearn.pipeline import make_pipeline"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["n_estimator = 10\n", "X, y = make_classification(n_samples=80000)\n", "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["It is important to train the ensemble of trees on a different subset<br>\n", "of the training data than the linear regression model to avoid<br>\n", "overfitting, in particular if the total number of leaves is<br>\n", "similar to the number of training samples"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X_train, X_train_lr, y_train, y_train_lr = train_test_split(\n", "    X_train, y_train, test_size=0.5)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Unsupervised transformation based on totally random trees"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["rt = RandomTreesEmbedding(max_depth=3, n_estimators=n_estimator,\n", "                          random_state=0)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["rt_lm = LogisticRegression(max_iter=1000)\n", "pipeline = make_pipeline(rt, rt_lm)\n", "pipeline.fit(X_train, y_train)\n", "y_pred_rt = pipeline.predict_proba(X_test)[:, 1]\n", "fpr_rt_lm, tpr_rt_lm, _ = roc_curve(y_test, y_pred_rt)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Supervised transformation based on random forests"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["rf = RandomForestClassifier(max_depth=3, n_estimators=n_estimator)\n", "rf_enc = OneHotEncoder()\n", "rf_lm = LogisticRegression(max_iter=1000)\n", "rf.fit(X_train, y_train)\n", "rf_enc.fit(rf.apply(X_train))\n", "rf_lm.fit(rf_enc.transform(rf.apply(X_train_lr)), y_train_lr)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["y_pred_rf_lm = rf_lm.predict_proba(rf_enc.transform(rf.apply(X_test)))[:, 1]\n", "fpr_rf_lm, tpr_rf_lm, _ = roc_curve(y_test, y_pred_rf_lm)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Supervised transformation based on gradient boosted trees"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["grd = GradientBoostingClassifier(n_estimators=n_estimator)\n", "grd_enc = OneHotEncoder()\n", "grd_lm = LogisticRegression(max_iter=1000)\n", "grd.fit(X_train, y_train)\n", "grd_enc.fit(grd.apply(X_train)[:, :, 0])\n", "grd_lm.fit(grd_enc.transform(grd.apply(X_train_lr)[:, :, 0]), y_train_lr)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["y_pred_grd_lm = grd_lm.predict_proba(\n", "    grd_enc.transform(grd.apply(X_test)[:, :, 0]))[:, 1]\n", "fpr_grd_lm, tpr_grd_lm, _ = roc_curve(y_test, y_pred_grd_lm)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["The gradient boosted model by itself"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["y_pred_grd = grd.predict_proba(X_test)[:, 1]\n", "fpr_grd, tpr_grd, _ = roc_curve(y_test, y_pred_grd)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["The random forest model by itself"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["y_pred_rf = rf.predict_proba(X_test)[:, 1]\n", "fpr_rf, tpr_rf, _ = roc_curve(y_test, y_pred_rf)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.figure(1)\n", "plt.plot([0, 1], [0, 1], 'k--')\n", "plt.plot(fpr_rt_lm, tpr_rt_lm, label='RT + LR')\n", "plt.plot(fpr_rf, tpr_rf, label='RF')\n", "plt.plot(fpr_rf_lm, tpr_rf_lm, label='RF + LR')\n", "plt.plot(fpr_grd, tpr_grd, label='GBT')\n", "plt.plot(fpr_grd_lm, tpr_grd_lm, label='GBT + LR')\n", "plt.xlabel('False positive rate')\n", "plt.ylabel('True positive rate')\n", "plt.title('ROC curve')\n", "plt.legend(loc='best')\n", "plt.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.figure(2)\n", "plt.xlim(0, 0.2)\n", "plt.ylim(0.8, 1)\n", "plt.plot([0, 1], [0, 1], 'k--')\n", "plt.plot(fpr_rt_lm, tpr_rt_lm, label='RT + LR')\n", "plt.plot(fpr_rf, tpr_rf, label='RF')\n", "plt.plot(fpr_rf_lm, tpr_rf_lm, label='RF + LR')\n", "plt.plot(fpr_grd, tpr_grd, label='GBT')\n", "plt.plot(fpr_grd_lm, tpr_grd_lm, label='GBT + LR')\n", "plt.xlabel('False positive rate')\n", "plt.ylabel('True positive rate')\n", "plt.title('ROC curve (zoomed in at top left)')\n", "plt.legend(loc='best')\n", "plt.show()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}