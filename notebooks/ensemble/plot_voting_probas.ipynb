{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "===========================================================<br>\n", "Plot class probabilities calculated by the VotingClassifier<br>\n", "===========================================================<br>\n", ".. currentmodule:: sklearn<br>\n", "Plot the class probabilities of the first sample in a toy dataset predicted by<br>\n", "three different classifiers and averaged by the<br>\n", ":class:`~ensemble.VotingClassifier`.<br>\n", "First, three examplary classifiers are initialized<br>\n", "(:class:`~linear_model.LogisticRegression`, :class:`~naive_bayes.GaussianNB`,<br>\n", "and :class:`~ensemble.RandomForestClassifier`) and used to initialize a<br>\n", "soft-voting :class:`~ensemble.VotingClassifier` with weights `[1, 1, 5]`, which<br>\n", "means that the predicted probabilities of the<br>\n", ":class:`~ensemble.RandomForestClassifier` count 5 times as much as the weights<br>\n", "of the other classifiers when the averaged probability is calculated.<br>\n", "To visualize the probability weighting, we fit each classifier on the training<br>\n", "set and plot the predicted class probabilities for the first sample in this<br>\n", "example dataset.<br>\n", ""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(__doc__)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "import matplotlib.pyplot as plt"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.linear_model import LogisticRegression\n", "from sklearn.naive_bayes import GaussianNB\n", "from sklearn.ensemble import RandomForestClassifier\n", "from sklearn.ensemble import VotingClassifier"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["clf1 = LogisticRegression(max_iter=1000, random_state=123)\n", "clf2 = RandomForestClassifier(n_estimators=100, random_state=123)\n", "clf3 = GaussianNB()\n", "X = np.array([[-1.0, -1.0], [-1.2, -1.4], [-3.4, -2.2], [1.1, 1.2]])\n", "y = np.array([1, 1, 2, 2])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["eclf = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)],\n", "                        voting='soft',\n", "                        weights=[1, 1, 5])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["predict class probabilities for all classifiers"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["probas = [c.fit(X, y).predict_proba(X) for c in (clf1, clf2, clf3, eclf)]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["get class probabilities for the first sample in the dataset"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class1_1 = [pr[0, 0] for pr in probas]\n", "class2_1 = [pr[0, 1] for pr in probas]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["plotting"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["N = 4  # number of groups\n", "ind = np.arange(N)  # group positions\n", "width = 0.35  # bar width"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fig, ax = plt.subplots()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["bars for classifier 1-3"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["p1 = ax.bar(ind, np.hstack(([class1_1[:-1], [0]])), width,\n", "            color='green', edgecolor='k')\n", "p2 = ax.bar(ind + width, np.hstack(([class2_1[:-1], [0]])), width,\n", "            color='lightgreen', edgecolor='k')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["bars for VotingClassifier"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["p3 = ax.bar(ind, [0, 0, 0, class1_1[-1]], width,\n", "            color='blue', edgecolor='k')\n", "p4 = ax.bar(ind + width, [0, 0, 0, class2_1[-1]], width,\n", "            color='steelblue', edgecolor='k')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["plot annotations"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.axvline(2.8, color='k', linestyle='dashed')\n", "ax.set_xticks(ind + width)\n", "ax.set_xticklabels(['LogisticRegression\\nweight 1',\n", "                    'GaussianNB\\nweight 1',\n", "                    'RandomForestClassifier\\nweight 5',\n", "                    'VotingClassifier\\n(average probabilities)'],\n", "                   rotation=40,\n", "                   ha='right')\n", "plt.ylim([0, 1])\n", "plt.title('Class probabilities for sample 1 by different classifiers')\n", "plt.legend([p1[0], p2[0]], ['class 1', 'class 2'], loc='upper left')\n", "plt.tight_layout()\n", "plt.show()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}